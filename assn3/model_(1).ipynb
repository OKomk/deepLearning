{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.optimizers import Adam, SGD, Adagrad, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, Callback\n",
    "from PIL import Image\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapDict = {0: 0, 3: 1, 5: 2, 6: 3, 7: 4}\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "folder_path = './Group_18/train'\n",
    "\n",
    "for foldername in os.listdir(folder_path):\n",
    "    for filename in os.listdir(os.path.join(folder_path, foldername)):\n",
    "\n",
    "        flattened = np.array(Image.open(os.path.join(folder_path, foldername, filename))).flatten()\n",
    "        flattened[flattened > 0] = 1\n",
    "        X_train.append(flattened)\n",
    "        y_train.append(int(foldername))\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "for i, n in enumerate(y_train):\n",
    "    y_train[i] = mapDict[y_train[i]]\n",
    "y_train = to_categorical(y_train, num_classes=5)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "folder_path = './Group_18/test'\n",
    "\n",
    "for foldername in os.listdir(folder_path):\n",
    "    for filename in os.listdir(os.path.join(folder_path, foldername)):\n",
    "\n",
    "        flattened = np.array(Image.open(os.path.join(folder_path, foldername, filename))).flatten()\n",
    "        flattened[flattened > 0] = 1\n",
    "        X_test.append(flattened)\n",
    "        y_test.append(int(foldername))\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "for i, n in enumerate(y_test):\n",
    "    y_test[i] = mapDict[y_test[i]]\n",
    "y_test = to_categorical(y_test, num_classes=5)\n",
    "\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "\n",
    "folder_path = './Group_18/val'\n",
    "\n",
    "for foldername in os.listdir(folder_path):\n",
    "    for filename in os.listdir(os.path.join(folder_path, foldername)):\n",
    "\n",
    "        flattened = np.array(Image.open(os.path.join(folder_path, foldername, filename))).flatten()\n",
    "        flattened[flattened > 0] = 1\n",
    "        X_val.append(flattened)\n",
    "        y_val.append(int(foldername))\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "for i, n in enumerate(y_val):\n",
    "    y_val[i] = mapDict[y_val[i]]\n",
    "y_val = to_categorical(y_val, num_classes=5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "        layers.Dense(1000, activation=\"sigmoid\", name=\"layer1\"),\n",
    "        layers.Dense(500, activation=\"sigmoid\", name=\"layer2\"),\n",
    "        layers.Dense(100, activation=\"sigmoid\", name=\"layer3\"),\n",
    "        layers.Dense(5, activation=\"softmax\", name=\"output\"),\n",
    "        ])\n",
    "model.build((None, 784))\n",
    "initial_weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_optimizer = SGD(learning_rate=0.001,name='SGD') #Normal Gradient Descent\n",
    "momentum_optimizer = SGD(learning_rate=0.001, momentum=0.9, name='Momentum_SGD') #Momentum Based\n",
    "nag_optimizer = SGD(learning_rate=0.001, momentum=0.9, nesterov=True, name='NAG') #NAG\n",
    "rms_optimizer = RMSprop(learning_rate=0.001, rho=0.99, momentum=0.0, epsilon=1e-08, name=\"RMSProp\") #RMSProp\n",
    "adagrad_optimizer = Adagrad(learning_rate=0.001, epsilon=1e-08, name=\"Adagrad\") #AdaGrad\n",
    "adam_optimizer = Adam(learning_rate=0.001) #Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\"model_checkpoint_Adagrad.h5\")\n",
    "class AverageLossCallback(Callback):\n",
    "   def __init__(self, patience=2, threshold=0.0005):\n",
    "      super().__init__()\n",
    "      self.patience = patience\n",
    "      self.threshold = threshold\n",
    "      self.best_loss = np.Inf\n",
    "      self.wait = 0\n",
    "      self.losses = []\n",
    "\n",
    "   def on_epoch_end(self, epoch, logs=None):\n",
    "      if logs is None:\n",
    "         logs = {}\n",
    "      train_loss = logs.get('loss')\n",
    "      if train_loss is None:\n",
    "         return\n",
    "      self.losses.append(train_loss)\n",
    "      if len(self.losses) > self.patience:\n",
    "         cur_loss = np.mean(self.losses[-self.patience:])\n",
    "         prev_loss = np.mean(self.losses[-self.patience-1:-1])\n",
    "         if abs(cur_loss - prev_loss) < self.threshold:\n",
    "               self.wait += 1\n",
    "               if self.wait >= self.patience:\n",
    "                  self.model.stop_training = True\n",
    "         else:\n",
    "               self.wait = 0\n",
    "               \n",
    "average_loss_callback = AverageLossCallback()\n",
    "my_callbacks = [\n",
    "   average_loss_callback]\n",
    "\n",
    "# ,\n",
    "#    ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "#    TensorBoard(log_dir='./logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs_dict = {} # number of epochs each optimizer took till convergence\n",
    "loss_dict = {} # loss at each epoch for each optimizer\n",
    "eval_dict = {} # (train_accuracy, val_accuracy) for each optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "11385/11385 [==============================] - 43s 4ms/step - loss: 0.5031 - accuracy: 0.2094 - val_loss: 0.4997 - val_accuracy: 0.2003\n",
      "Epoch 2/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.4990 - accuracy: 0.2448 - val_loss: 0.4980 - val_accuracy: 0.4532\n",
      "Epoch 3/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.4976 - accuracy: 0.2584 - val_loss: 0.4966 - val_accuracy: 0.3557\n",
      "Epoch 4/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.4964 - accuracy: 0.3185 - val_loss: 0.4954 - val_accuracy: 0.3323\n",
      "Epoch 5/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.4948 - accuracy: 0.3230 - val_loss: 0.4939 - val_accuracy: 0.3107\n",
      "Epoch 6/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.4930 - accuracy: 0.3784 - val_loss: 0.4917 - val_accuracy: 0.5133\n",
      "Epoch 7/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.4909 - accuracy: 0.4160 - val_loss: 0.4897 - val_accuracy: 0.3887\n",
      "Epoch 8/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.4884 - accuracy: 0.4750 - val_loss: 0.4868 - val_accuracy: 0.5597\n",
      "Epoch 9/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.4853 - accuracy: 0.5209 - val_loss: 0.4834 - val_accuracy: 0.5897\n",
      "Epoch 10/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.4812 - accuracy: 0.5626 - val_loss: 0.4791 - val_accuracy: 0.4735\n",
      "Epoch 11/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.4760 - accuracy: 0.5753 - val_loss: 0.4732 - val_accuracy: 0.5765\n",
      "Epoch 12/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.4691 - accuracy: 0.5998 - val_loss: 0.4654 - val_accuracy: 0.5781\n",
      "Epoch 13/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.4600 - accuracy: 0.6117 - val_loss: 0.4547 - val_accuracy: 0.5418\n",
      "Epoch 14/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.4480 - accuracy: 0.5979 - val_loss: 0.4412 - val_accuracy: 0.6163\n",
      "Epoch 15/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.4332 - accuracy: 0.6111 - val_loss: 0.4252 - val_accuracy: 0.6161\n",
      "Epoch 16/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.4167 - accuracy: 0.6194 - val_loss: 0.4088 - val_accuracy: 0.5673\n",
      "Epoch 17/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.4000 - accuracy: 0.6201 - val_loss: 0.3924 - val_accuracy: 0.6208\n",
      "Epoch 18/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.3839 - accuracy: 0.6422 - val_loss: 0.3770 - val_accuracy: 0.6013\n",
      "Epoch 19/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.3683 - accuracy: 0.6588 - val_loss: 0.3617 - val_accuracy: 0.6292\n",
      "Epoch 20/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.3528 - accuracy: 0.6791 - val_loss: 0.3455 - val_accuracy: 0.6730\n",
      "Epoch 21/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.3361 - accuracy: 0.7063 - val_loss: 0.3288 - val_accuracy: 0.6870\n",
      "Epoch 22/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.3184 - accuracy: 0.7206 - val_loss: 0.3118 - val_accuracy: 0.7378\n",
      "Epoch 23/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.3006 - accuracy: 0.7461 - val_loss: 0.2941 - val_accuracy: 0.7265\n",
      "Epoch 24/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.2834 - accuracy: 0.7581 - val_loss: 0.2776 - val_accuracy: 0.7694\n",
      "Epoch 25/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.2672 - accuracy: 0.7769 - val_loss: 0.2623 - val_accuracy: 0.7531\n",
      "Epoch 26/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.2526 - accuracy: 0.7891 - val_loss: 0.2487 - val_accuracy: 0.7679\n",
      "Epoch 27/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.2395 - accuracy: 0.7989 - val_loss: 0.2362 - val_accuracy: 0.7992\n",
      "Epoch 28/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.2277 - accuracy: 0.8088 - val_loss: 0.2252 - val_accuracy: 0.8097\n",
      "Epoch 29/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.2170 - accuracy: 0.8189 - val_loss: 0.2158 - val_accuracy: 0.8079\n",
      "Epoch 30/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.2075 - accuracy: 0.8284 - val_loss: 0.2060 - val_accuracy: 0.8219\n",
      "Epoch 31/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.1986 - accuracy: 0.8382 - val_loss: 0.1982 - val_accuracy: 0.8303\n",
      "Epoch 32/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.1903 - accuracy: 0.8468 - val_loss: 0.1898 - val_accuracy: 0.8390\n",
      "Epoch 33/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.1826 - accuracy: 0.8552 - val_loss: 0.1821 - val_accuracy: 0.8567\n",
      "Epoch 34/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.1753 - accuracy: 0.8636 - val_loss: 0.1751 - val_accuracy: 0.8603\n",
      "Epoch 35/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.1683 - accuracy: 0.8701 - val_loss: 0.1687 - val_accuracy: 0.8677\n",
      "Epoch 36/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.1619 - accuracy: 0.8767 - val_loss: 0.1631 - val_accuracy: 0.8651\n",
      "Epoch 37/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.1557 - accuracy: 0.8823 - val_loss: 0.1571 - val_accuracy: 0.8746\n",
      "Epoch 38/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.1500 - accuracy: 0.8878 - val_loss: 0.1515 - val_accuracy: 0.8822\n",
      "Epoch 39/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.1444 - accuracy: 0.8933 - val_loss: 0.1462 - val_accuracy: 0.8864\n",
      "Epoch 40/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.1395 - accuracy: 0.8967 - val_loss: 0.1414 - val_accuracy: 0.8930\n",
      "Epoch 41/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.1346 - accuracy: 0.9021 - val_loss: 0.1376 - val_accuracy: 0.8949\n",
      "Epoch 42/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.1302 - accuracy: 0.9032 - val_loss: 0.1326 - val_accuracy: 0.8970\n",
      "Epoch 43/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.1258 - accuracy: 0.9071 - val_loss: 0.1289 - val_accuracy: 0.9001\n",
      "Epoch 44/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.1218 - accuracy: 0.9092 - val_loss: 0.1251 - val_accuracy: 0.9004\n",
      "Epoch 45/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.1180 - accuracy: 0.9137 - val_loss: 0.1218 - val_accuracy: 0.9049\n",
      "Epoch 46/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.1143 - accuracy: 0.9179 - val_loss: 0.1186 - val_accuracy: 0.9041\n",
      "Epoch 47/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.1110 - accuracy: 0.9206 - val_loss: 0.1159 - val_accuracy: 0.9078\n",
      "Epoch 48/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.1078 - accuracy: 0.9217 - val_loss: 0.1132 - val_accuracy: 0.9130\n",
      "Epoch 49/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.1050 - accuracy: 0.9253 - val_loss: 0.1103 - val_accuracy: 0.9159\n",
      "Epoch 50/1000\n",
      "11385/11385 [==============================] - 44s 4ms/step - loss: 0.1022 - accuracy: 0.9276 - val_loss: 0.1078 - val_accuracy: 0.9141\n",
      "Epoch 51/1000\n",
      "11385/11385 [==============================] - 44s 4ms/step - loss: 0.0996 - accuracy: 0.9288 - val_loss: 0.1057 - val_accuracy: 0.9159\n",
      "Epoch 52/1000\n",
      "11385/11385 [==============================] - 46s 4ms/step - loss: 0.0973 - accuracy: 0.9303 - val_loss: 0.1036 - val_accuracy: 0.9157\n",
      "Epoch 53/1000\n",
      "11385/11385 [==============================] - 48s 4ms/step - loss: 0.0951 - accuracy: 0.9327 - val_loss: 0.1026 - val_accuracy: 0.9175\n",
      "Epoch 54/1000\n",
      "11385/11385 [==============================] - 48s 4ms/step - loss: 0.0930 - accuracy: 0.9332 - val_loss: 0.0999 - val_accuracy: 0.9183\n",
      "Epoch 55/1000\n",
      "11385/11385 [==============================] - 49s 4ms/step - loss: 0.0910 - accuracy: 0.9346 - val_loss: 0.0988 - val_accuracy: 0.9228\n",
      "Epoch 56/1000\n",
      "11385/11385 [==============================] - 47s 4ms/step - loss: 0.0892 - accuracy: 0.9361 - val_loss: 0.0968 - val_accuracy: 0.9209\n",
      "Epoch 57/1000\n",
      "11385/11385 [==============================] - 49s 4ms/step - loss: 0.0876 - accuracy: 0.9365 - val_loss: 0.0957 - val_accuracy: 0.9228\n",
      "Epoch 58/1000\n",
      "11385/11385 [==============================] - 46s 4ms/step - loss: 0.0859 - accuracy: 0.9381 - val_loss: 0.0940 - val_accuracy: 0.9252\n",
      "Epoch 59/1000\n",
      "11385/11385 [==============================] - 47s 4ms/step - loss: 0.0843 - accuracy: 0.9390 - val_loss: 0.0937 - val_accuracy: 0.9212\n",
      "Epoch 60/1000\n",
      "11385/11385 [==============================] - 44s 4ms/step - loss: 0.0830 - accuracy: 0.9397 - val_loss: 0.0918 - val_accuracy: 0.9233\n",
      "Epoch 61/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.0815 - accuracy: 0.9411 - val_loss: 0.0906 - val_accuracy: 0.9249\n",
      "Epoch 62/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.0803 - accuracy: 0.9404 - val_loss: 0.0902 - val_accuracy: 0.9262\n",
      "Epoch 63/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.0791 - accuracy: 0.9432 - val_loss: 0.0886 - val_accuracy: 0.9252\n",
      "Epoch 64/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.0779 - accuracy: 0.9419 - val_loss: 0.0880 - val_accuracy: 0.9265\n",
      "Epoch 65/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.0769 - accuracy: 0.9441 - val_loss: 0.0868 - val_accuracy: 0.9270\n",
      "Epoch 66/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.0757 - accuracy: 0.9441 - val_loss: 0.0873 - val_accuracy: 0.9246\n",
      "Epoch 67/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.0747 - accuracy: 0.9449 - val_loss: 0.0857 - val_accuracy: 0.9278\n",
      "Epoch 68/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.0737 - accuracy: 0.9458 - val_loss: 0.0857 - val_accuracy: 0.9275\n",
      "Epoch 69/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.0728 - accuracy: 0.9467 - val_loss: 0.0841 - val_accuracy: 0.9275\n",
      "Epoch 70/1000\n",
      "11385/11385 [==============================] - 45s 4ms/step - loss: 0.0718 - accuracy: 0.9482 - val_loss: 0.0842 - val_accuracy: 0.9265\n",
      "Epoch 71/1000\n",
      "11385/11385 [==============================] - 44s 4ms/step - loss: 0.0711 - accuracy: 0.9484 - val_loss: 0.0831 - val_accuracy: 0.9275\n",
      "Epoch 72/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.0703 - accuracy: 0.9482 - val_loss: 0.0828 - val_accuracy: 0.9281\n",
      "Epoch 73/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.0693 - accuracy: 0.9491 - val_loss: 0.0822 - val_accuracy: 0.9320\n",
      "Epoch 74/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.0686 - accuracy: 0.9495 - val_loss: 0.0815 - val_accuracy: 0.9333\n",
      "Epoch 75/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.0678 - accuracy: 0.9500 - val_loss: 0.0822 - val_accuracy: 0.9286\n",
      "Epoch 76/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.0671 - accuracy: 0.9512 - val_loss: 0.0802 - val_accuracy: 0.9323\n",
      "Epoch 77/1000\n",
      "11385/11385 [==============================] - 45s 4ms/step - loss: 0.0665 - accuracy: 0.9504 - val_loss: 0.0811 - val_accuracy: 0.9312\n",
      "Epoch 78/1000\n",
      "11385/11385 [==============================] - 47s 4ms/step - loss: 0.0658 - accuracy: 0.9503 - val_loss: 0.0795 - val_accuracy: 0.9318\n",
      "Epoch 79/1000\n",
      "11385/11385 [==============================] - 46s 4ms/step - loss: 0.0651 - accuracy: 0.9518 - val_loss: 0.0800 - val_accuracy: 0.9323\n",
      "Epoch 80/1000\n",
      "11385/11385 [==============================] - 47s 4ms/step - loss: 0.0643 - accuracy: 0.9531 - val_loss: 0.0794 - val_accuracy: 0.9347\n",
      "Epoch 81/1000\n",
      "11385/11385 [==============================] - 45s 4ms/step - loss: 0.0638 - accuracy: 0.9524 - val_loss: 0.0787 - val_accuracy: 0.9325\n",
      "Epoch 82/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.0632 - accuracy: 0.9534 - val_loss: 0.0784 - val_accuracy: 0.9323\n",
      "Epoch 83/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.0625 - accuracy: 0.9532 - val_loss: 0.0778 - val_accuracy: 0.9325\n",
      "Epoch 84/1000\n",
      "11385/11385 [==============================] - 41s 4ms/step - loss: 0.0619 - accuracy: 0.9544 - val_loss: 0.0778 - val_accuracy: 0.9318\n",
      "Epoch 85/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.0613 - accuracy: 0.9529 - val_loss: 0.0777 - val_accuracy: 0.9315\n",
      "Epoch 86/1000\n",
      "11385/11385 [==============================] - 42s 4ms/step - loss: 0.0609 - accuracy: 0.9544 - val_loss: 0.0775 - val_accuracy: 0.9315\n",
      "Epoch 87/1000\n",
      "11385/11385 [==============================] - 44s 4ms/step - loss: 0.0604 - accuracy: 0.9545 - val_loss: 0.0775 - val_accuracy: 0.9310\n"
     ]
    }
   ],
   "source": [
    "# SGD Optimizer\n",
    "model.set_weights(initial_weights)\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd_optimizer)\n",
    "model_fit = model.fit(x=X_train, y=y_train, batch_size=1, epochs=1000, verbose=\"auto\", callbacks=[\n",
    "   average_loss_callback,\n",
    "   ModelCheckpoint(filepath=f\"model_checkpoint_{model.optimizer.get_config()['name']}.h5\",\n",
    "                   save_best_only=True,  # Only save the best performing model\n",
    "                    monitor='loss',  # Monitor the validation loss\n",
    "                    mode='min',          # Minimize the validation loss\n",
    "                    save_weights_only=False, # Save the entire model (including optimizer state)\n",
    "                    append_history=True,),\n",
    "   TensorBoard(log_dir='./logs')],\n",
    "    validation_split=0.0, validation_data=(X_val, y_val), shuffle=True, validation_batch_size=None)\n",
    "\n",
    "train_loss_list = model_fit.history['loss']\n",
    "\n",
    "num_epochs = len(model_fit.epoch)\n",
    "num_epochs_dict['SGD'] = num_epochs\n",
    "loss_dict['SGD'] = train_loss_list\n",
    "\n",
    "train_accuracy, val_accuracy = model_fit.history['accuracy'][-1], model_fit.history['val_accuracy'][-1]\n",
    "\n",
    "eval_dict['SGD'] = (train_accuracy, val_accuracy) \n",
    "\n",
    "with open('model_history_sgd.pkl', 'wb') as f:\n",
    "    pickle.dump(model_fit.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 1s 984ms/step - loss: 0.6263 - accuracy: 0.2000 - val_loss: 0.6257 - val_accuracy: 0.2000\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 429ms/step - loss: 0.6258 - accuracy: 0.2000 - val_loss: 0.6253 - val_accuracy: 0.2000\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.6253 - accuracy: 0.2000 - val_loss: 0.6248 - val_accuracy: 0.2000\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.6248 - accuracy: 0.2000 - val_loss: 0.6243 - val_accuracy: 0.2000\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.6244 - accuracy: 0.2000 - val_loss: 0.6238 - val_accuracy: 0.2000\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.6239 - accuracy: 0.2000 - val_loss: 0.6233 - val_accuracy: 0.2000\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 405ms/step - loss: 0.6234 - accuracy: 0.2000 - val_loss: 0.6228 - val_accuracy: 0.2000\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.6229 - accuracy: 0.2000 - val_loss: 0.6223 - val_accuracy: 0.2000\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.6224 - accuracy: 0.2000 - val_loss: 0.6219 - val_accuracy: 0.2000\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.6219 - accuracy: 0.2000 - val_loss: 0.6214 - val_accuracy: 0.2000\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.6215 - accuracy: 0.2000 - val_loss: 0.6209 - val_accuracy: 0.2000\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.6210 - accuracy: 0.2000 - val_loss: 0.6204 - val_accuracy: 0.2000\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.6205 - accuracy: 0.2000 - val_loss: 0.6200 - val_accuracy: 0.2000\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.6200 - accuracy: 0.2000 - val_loss: 0.6195 - val_accuracy: 0.2000\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.6196 - accuracy: 0.2000 - val_loss: 0.6190 - val_accuracy: 0.2000\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.6191 - accuracy: 0.2000 - val_loss: 0.6186 - val_accuracy: 0.2000\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.6186 - accuracy: 0.2000 - val_loss: 0.6181 - val_accuracy: 0.2000\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.6182 - accuracy: 0.2000 - val_loss: 0.6176 - val_accuracy: 0.2000\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.6177 - accuracy: 0.2000 - val_loss: 0.6172 - val_accuracy: 0.2000\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.6173 - accuracy: 0.2000 - val_loss: 0.6167 - val_accuracy: 0.2000\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.6168 - accuracy: 0.2000 - val_loss: 0.6163 - val_accuracy: 0.2000\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.6163 - accuracy: 0.2000 - val_loss: 0.6158 - val_accuracy: 0.2000\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.6159 - accuracy: 0.2000 - val_loss: 0.6154 - val_accuracy: 0.2000\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.6154 - accuracy: 0.2000 - val_loss: 0.6149 - val_accuracy: 0.2000\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.6150 - accuracy: 0.2000 - val_loss: 0.6145 - val_accuracy: 0.2000\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.6145 - accuracy: 0.2000 - val_loss: 0.6140 - val_accuracy: 0.2000\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.6141 - accuracy: 0.2000 - val_loss: 0.6136 - val_accuracy: 0.2000\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.6137 - accuracy: 0.2000 - val_loss: 0.6131 - val_accuracy: 0.2000\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.6132 - accuracy: 0.2000 - val_loss: 0.6127 - val_accuracy: 0.2000\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 0.6128 - accuracy: 0.2000 - val_loss: 0.6123 - val_accuracy: 0.2000\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.6123 - accuracy: 0.2000 - val_loss: 0.6118 - val_accuracy: 0.2000\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.6119 - accuracy: 0.2000 - val_loss: 0.6114 - val_accuracy: 0.2000\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.6115 - accuracy: 0.2000 - val_loss: 0.6110 - val_accuracy: 0.2000\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.6110 - accuracy: 0.2000 - val_loss: 0.6105 - val_accuracy: 0.2000\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.6106 - accuracy: 0.2000 - val_loss: 0.6101 - val_accuracy: 0.2000\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.6102 - accuracy: 0.2000 - val_loss: 0.6097 - val_accuracy: 0.2000\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.6097 - accuracy: 0.2000 - val_loss: 0.6092 - val_accuracy: 0.2000\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.6093 - accuracy: 0.2000 - val_loss: 0.6088 - val_accuracy: 0.2000\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.6089 - accuracy: 0.2000 - val_loss: 0.6084 - val_accuracy: 0.2000\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.6085 - accuracy: 0.2000 - val_loss: 0.6080 - val_accuracy: 0.2000\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.6080 - accuracy: 0.2000 - val_loss: 0.6076 - val_accuracy: 0.2000\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.6076 - accuracy: 0.2000 - val_loss: 0.6071 - val_accuracy: 0.2000\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.6072 - accuracy: 0.2000 - val_loss: 0.6067 - val_accuracy: 0.2000\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.6068 - accuracy: 0.2000 - val_loss: 0.6063 - val_accuracy: 0.2000\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.6064 - accuracy: 0.2000 - val_loss: 0.6059 - val_accuracy: 0.2000\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.6060 - accuracy: 0.2000 - val_loss: 0.6055 - val_accuracy: 0.2000\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.6056 - accuracy: 0.2000 - val_loss: 0.6051 - val_accuracy: 0.2000\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.6051 - accuracy: 0.2000 - val_loss: 0.6047 - val_accuracy: 0.2000\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.6047 - accuracy: 0.2000 - val_loss: 0.6043 - val_accuracy: 0.2000\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.6043 - accuracy: 0.2000 - val_loss: 0.6039 - val_accuracy: 0.2000\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.6039 - accuracy: 0.2000 - val_loss: 0.6035 - val_accuracy: 0.2000\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.6035 - accuracy: 0.2000 - val_loss: 0.6031 - val_accuracy: 0.2000\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.6031 - accuracy: 0.2000 - val_loss: 0.6027 - val_accuracy: 0.2000\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.6027 - accuracy: 0.2000 - val_loss: 0.6023 - val_accuracy: 0.2000\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.6023 - accuracy: 0.2000 - val_loss: 0.6019 - val_accuracy: 0.2000\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 0.6019 - accuracy: 0.2000 - val_loss: 0.6015 - val_accuracy: 0.2000\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.6015 - accuracy: 0.2000 - val_loss: 0.6011 - val_accuracy: 0.2000\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.6012 - accuracy: 0.2000 - val_loss: 0.6007 - val_accuracy: 0.2000\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.6008 - accuracy: 0.2000 - val_loss: 0.6003 - val_accuracy: 0.2000\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.6004 - accuracy: 0.2000 - val_loss: 0.5999 - val_accuracy: 0.2000\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.6000 - accuracy: 0.2000 - val_loss: 0.5995 - val_accuracy: 0.2000\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5996 - accuracy: 0.2000 - val_loss: 0.5991 - val_accuracy: 0.2000\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5992 - accuracy: 0.2000 - val_loss: 0.5988 - val_accuracy: 0.2000\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5988 - accuracy: 0.2000 - val_loss: 0.5984 - val_accuracy: 0.2000\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.5984 - accuracy: 0.2000 - val_loss: 0.5980 - val_accuracy: 0.2000\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5981 - accuracy: 0.2000 - val_loss: 0.5976 - val_accuracy: 0.2000\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5977 - accuracy: 0.2000 - val_loss: 0.5972 - val_accuracy: 0.2000\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5973 - accuracy: 0.2000 - val_loss: 0.5969 - val_accuracy: 0.2000\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5969 - accuracy: 0.2000 - val_loss: 0.5965 - val_accuracy: 0.2000\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5966 - accuracy: 0.2000 - val_loss: 0.5961 - val_accuracy: 0.2000\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5962 - accuracy: 0.2000 - val_loss: 0.5957 - val_accuracy: 0.2000\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5958 - accuracy: 0.2000 - val_loss: 0.5954 - val_accuracy: 0.2000\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.5955 - accuracy: 0.2000 - val_loss: 0.5950 - val_accuracy: 0.2000\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5951 - accuracy: 0.2000 - val_loss: 0.5946 - val_accuracy: 0.2000\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5947 - accuracy: 0.2000 - val_loss: 0.5943 - val_accuracy: 0.2000\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5944 - accuracy: 0.2000 - val_loss: 0.5939 - val_accuracy: 0.2000\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5940 - accuracy: 0.2000 - val_loss: 0.5936 - val_accuracy: 0.2000\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5936 - accuracy: 0.2000 - val_loss: 0.5932 - val_accuracy: 0.2000\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5933 - accuracy: 0.2000 - val_loss: 0.5928 - val_accuracy: 0.2000\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5929 - accuracy: 0.2000 - val_loss: 0.5925 - val_accuracy: 0.2000\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5926 - accuracy: 0.2000 - val_loss: 0.5921 - val_accuracy: 0.2000\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5922 - accuracy: 0.2000 - val_loss: 0.5918 - val_accuracy: 0.2000\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5919 - accuracy: 0.2000 - val_loss: 0.5914 - val_accuracy: 0.2000\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5915 - accuracy: 0.2000 - val_loss: 0.5911 - val_accuracy: 0.2000\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5912 - accuracy: 0.2000 - val_loss: 0.5907 - val_accuracy: 0.2000\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5908 - accuracy: 0.2000 - val_loss: 0.5904 - val_accuracy: 0.2000\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5905 - accuracy: 0.2000 - val_loss: 0.5900 - val_accuracy: 0.2000\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5901 - accuracy: 0.2000 - val_loss: 0.5897 - val_accuracy: 0.2000\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5898 - accuracy: 0.2000 - val_loss: 0.5893 - val_accuracy: 0.2000\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5894 - accuracy: 0.2000 - val_loss: 0.5890 - val_accuracy: 0.2000\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5891 - accuracy: 0.2000 - val_loss: 0.5887 - val_accuracy: 0.2000\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5887 - accuracy: 0.2000 - val_loss: 0.5883 - val_accuracy: 0.2000\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5884 - accuracy: 0.2000 - val_loss: 0.5880 - val_accuracy: 0.2000\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5881 - accuracy: 0.2000 - val_loss: 0.5876 - val_accuracy: 0.2000\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5877 - accuracy: 0.2000 - val_loss: 0.5873 - val_accuracy: 0.2000\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5874 - accuracy: 0.2000 - val_loss: 0.5870 - val_accuracy: 0.2000\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5871 - accuracy: 0.2000 - val_loss: 0.5866 - val_accuracy: 0.2000\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5867 - accuracy: 0.2000 - val_loss: 0.5863 - val_accuracy: 0.2000\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5864 - accuracy: 0.2000 - val_loss: 0.5860 - val_accuracy: 0.2000\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5861 - accuracy: 0.2000 - val_loss: 0.5857 - val_accuracy: 0.2000\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5857 - accuracy: 0.2000 - val_loss: 0.5853 - val_accuracy: 0.2000\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5854 - accuracy: 0.2000 - val_loss: 0.5850 - val_accuracy: 0.2000\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5851 - accuracy: 0.2000 - val_loss: 0.5847 - val_accuracy: 0.2000\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5848 - accuracy: 0.2000 - val_loss: 0.5844 - val_accuracy: 0.2000\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5844 - accuracy: 0.2000 - val_loss: 0.5840 - val_accuracy: 0.2000\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5841 - accuracy: 0.2000 - val_loss: 0.5837 - val_accuracy: 0.2000\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5838 - accuracy: 0.2000 - val_loss: 0.5834 - val_accuracy: 0.2000\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5835 - accuracy: 0.2000 - val_loss: 0.5831 - val_accuracy: 0.2000\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5832 - accuracy: 0.2000 - val_loss: 0.5828 - val_accuracy: 0.2000\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5828 - accuracy: 0.2000 - val_loss: 0.5824 - val_accuracy: 0.2000\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5825 - accuracy: 0.2000 - val_loss: 0.5821 - val_accuracy: 0.2000\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5822 - accuracy: 0.2000 - val_loss: 0.5818 - val_accuracy: 0.2000\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5819 - accuracy: 0.2000 - val_loss: 0.5815 - val_accuracy: 0.2000\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5816 - accuracy: 0.2000 - val_loss: 0.5812 - val_accuracy: 0.2000\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.5813 - accuracy: 0.2000 - val_loss: 0.5809 - val_accuracy: 0.2000\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5810 - accuracy: 0.2000 - val_loss: 0.5806 - val_accuracy: 0.2000\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5807 - accuracy: 0.2000 - val_loss: 0.5803 - val_accuracy: 0.2000\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.5804 - accuracy: 0.2000 - val_loss: 0.5800 - val_accuracy: 0.2000\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5800 - accuracy: 0.2000 - val_loss: 0.5797 - val_accuracy: 0.2000\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5797 - accuracy: 0.2000 - val_loss: 0.5794 - val_accuracy: 0.2000\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5794 - accuracy: 0.2000 - val_loss: 0.5791 - val_accuracy: 0.2000\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5791 - accuracy: 0.2000 - val_loss: 0.5788 - val_accuracy: 0.2000\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5788 - accuracy: 0.2000 - val_loss: 0.5785 - val_accuracy: 0.2000\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5785 - accuracy: 0.2000 - val_loss: 0.5782 - val_accuracy: 0.2000\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5782 - accuracy: 0.2000 - val_loss: 0.5779 - val_accuracy: 0.2000\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5779 - accuracy: 0.2000 - val_loss: 0.5776 - val_accuracy: 0.2000\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5777 - accuracy: 0.2000 - val_loss: 0.5773 - val_accuracy: 0.2000\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5774 - accuracy: 0.2000 - val_loss: 0.5770 - val_accuracy: 0.2000\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5771 - accuracy: 0.2000 - val_loss: 0.5767 - val_accuracy: 0.2000\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5768 - accuracy: 0.2000 - val_loss: 0.5764 - val_accuracy: 0.2000\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5765 - accuracy: 0.2000 - val_loss: 0.5761 - val_accuracy: 0.2000\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5762 - accuracy: 0.2000 - val_loss: 0.5758 - val_accuracy: 0.2000\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5759 - accuracy: 0.2000 - val_loss: 0.5755 - val_accuracy: 0.2000\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5756 - accuracy: 0.2000 - val_loss: 0.5753 - val_accuracy: 0.2000\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5753 - accuracy: 0.2000 - val_loss: 0.5750 - val_accuracy: 0.2000\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5751 - accuracy: 0.2000 - val_loss: 0.5747 - val_accuracy: 0.2000\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5748 - accuracy: 0.2000 - val_loss: 0.5744 - val_accuracy: 0.2000\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5745 - accuracy: 0.2000 - val_loss: 0.5741 - val_accuracy: 0.2000\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5742 - accuracy: 0.2000 - val_loss: 0.5739 - val_accuracy: 0.2000\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5739 - accuracy: 0.2000 - val_loss: 0.5736 - val_accuracy: 0.2000\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5737 - accuracy: 0.2000 - val_loss: 0.5733 - val_accuracy: 0.2000\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5734 - accuracy: 0.2000 - val_loss: 0.5730 - val_accuracy: 0.2000\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5731 - accuracy: 0.2000 - val_loss: 0.5727 - val_accuracy: 0.2000\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5728 - accuracy: 0.2000 - val_loss: 0.5725 - val_accuracy: 0.2000\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5725 - accuracy: 0.2000 - val_loss: 0.5722 - val_accuracy: 0.2000\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5723 - accuracy: 0.2000 - val_loss: 0.5719 - val_accuracy: 0.2000\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5720 - accuracy: 0.2000 - val_loss: 0.5717 - val_accuracy: 0.2000\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5717 - accuracy: 0.2000 - val_loss: 0.5714 - val_accuracy: 0.2000\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5715 - accuracy: 0.2000 - val_loss: 0.5711 - val_accuracy: 0.2000\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5712 - accuracy: 0.2000 - val_loss: 0.5709 - val_accuracy: 0.2000\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5709 - accuracy: 0.2000 - val_loss: 0.5706 - val_accuracy: 0.2000\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.5707 - accuracy: 0.2000 - val_loss: 0.5703 - val_accuracy: 0.2000\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5704 - accuracy: 0.2000 - val_loss: 0.5701 - val_accuracy: 0.2000\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5701 - accuracy: 0.2000 - val_loss: 0.5698 - val_accuracy: 0.2000\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5699 - accuracy: 0.2000 - val_loss: 0.5695 - val_accuracy: 0.2000\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5696 - accuracy: 0.2000 - val_loss: 0.5693 - val_accuracy: 0.2000\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5693 - accuracy: 0.2000 - val_loss: 0.5690 - val_accuracy: 0.2000\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5691 - accuracy: 0.2000 - val_loss: 0.5688 - val_accuracy: 0.2000\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5688 - accuracy: 0.2000 - val_loss: 0.5685 - val_accuracy: 0.2000\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5686 - accuracy: 0.2000 - val_loss: 0.5682 - val_accuracy: 0.2000\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5683 - accuracy: 0.2000 - val_loss: 0.5680 - val_accuracy: 0.2000\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5681 - accuracy: 0.2000 - val_loss: 0.5677 - val_accuracy: 0.2000\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5678 - accuracy: 0.2000 - val_loss: 0.5675 - val_accuracy: 0.2000\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5676 - accuracy: 0.2000 - val_loss: 0.5672 - val_accuracy: 0.2000\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5673 - accuracy: 0.2000 - val_loss: 0.5670 - val_accuracy: 0.2000\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5670 - accuracy: 0.2000 - val_loss: 0.5667 - val_accuracy: 0.2000\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5668 - accuracy: 0.2000 - val_loss: 0.5665 - val_accuracy: 0.2000\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5665 - accuracy: 0.2000 - val_loss: 0.5662 - val_accuracy: 0.2000\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5663 - accuracy: 0.2000 - val_loss: 0.5660 - val_accuracy: 0.2000\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5661 - accuracy: 0.2000 - val_loss: 0.5657 - val_accuracy: 0.2000\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5658 - accuracy: 0.2000 - val_loss: 0.5655 - val_accuracy: 0.2000\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5656 - accuracy: 0.2000 - val_loss: 0.5652 - val_accuracy: 0.2000\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5653 - accuracy: 0.2000 - val_loss: 0.5650 - val_accuracy: 0.2000\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5651 - accuracy: 0.2000 - val_loss: 0.5648 - val_accuracy: 0.2000\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5648 - accuracy: 0.2000 - val_loss: 0.5645 - val_accuracy: 0.2000\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5646 - accuracy: 0.2000 - val_loss: 0.5643 - val_accuracy: 0.2000\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5644 - accuracy: 0.2000 - val_loss: 0.5640 - val_accuracy: 0.2000\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5641 - accuracy: 0.2000 - val_loss: 0.5638 - val_accuracy: 0.2000\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5639 - accuracy: 0.2000 - val_loss: 0.5636 - val_accuracy: 0.2000\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5636 - accuracy: 0.2000 - val_loss: 0.5633 - val_accuracy: 0.2000\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5634 - accuracy: 0.2000 - val_loss: 0.5631 - val_accuracy: 0.2000\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5632 - accuracy: 0.2000 - val_loss: 0.5629 - val_accuracy: 0.2000\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5629 - accuracy: 0.2000 - val_loss: 0.5626 - val_accuracy: 0.2000\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5627 - accuracy: 0.2000 - val_loss: 0.5624 - val_accuracy: 0.2000\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5625 - accuracy: 0.2000 - val_loss: 0.5622 - val_accuracy: 0.2000\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5622 - accuracy: 0.2000 - val_loss: 0.5619 - val_accuracy: 0.2000\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5620 - accuracy: 0.2000 - val_loss: 0.5617 - val_accuracy: 0.2000\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5618 - accuracy: 0.2000 - val_loss: 0.5615 - val_accuracy: 0.2000\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5615 - accuracy: 0.2000 - val_loss: 0.5612 - val_accuracy: 0.2000\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5613 - accuracy: 0.2000 - val_loss: 0.5610 - val_accuracy: 0.2000\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5611 - accuracy: 0.2000 - val_loss: 0.5608 - val_accuracy: 0.2000\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5609 - accuracy: 0.2000 - val_loss: 0.5606 - val_accuracy: 0.2000\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5606 - accuracy: 0.2000 - val_loss: 0.5603 - val_accuracy: 0.2000\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5604 - accuracy: 0.2000 - val_loss: 0.5601 - val_accuracy: 0.2000\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.5602 - accuracy: 0.2000 - val_loss: 0.5599 - val_accuracy: 0.2000\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.5600 - accuracy: 0.2000 - val_loss: 0.5597 - val_accuracy: 0.2000\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 403ms/step - loss: 0.5597 - accuracy: 0.2000 - val_loss: 0.5594 - val_accuracy: 0.2000\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5595 - accuracy: 0.2000 - val_loss: 0.5592 - val_accuracy: 0.2000\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5593 - accuracy: 0.2000 - val_loss: 0.5590 - val_accuracy: 0.2000\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5591 - accuracy: 0.2000 - val_loss: 0.5588 - val_accuracy: 0.2000\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5589 - accuracy: 0.2000 - val_loss: 0.5586 - val_accuracy: 0.2000\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5587 - accuracy: 0.2000 - val_loss: 0.5584 - val_accuracy: 0.2000\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5584 - accuracy: 0.2000 - val_loss: 0.5581 - val_accuracy: 0.2000\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5582 - accuracy: 0.2000 - val_loss: 0.5579 - val_accuracy: 0.2000\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5580 - accuracy: 0.2000 - val_loss: 0.5577 - val_accuracy: 0.2000\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5578 - accuracy: 0.2000 - val_loss: 0.5575 - val_accuracy: 0.2000\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5576 - accuracy: 0.2000 - val_loss: 0.5573 - val_accuracy: 0.2000\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5574 - accuracy: 0.2000 - val_loss: 0.5571 - val_accuracy: 0.2000\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5572 - accuracy: 0.2000 - val_loss: 0.5569 - val_accuracy: 0.2000\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5569 - accuracy: 0.2000 - val_loss: 0.5567 - val_accuracy: 0.2000\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5567 - accuracy: 0.2000 - val_loss: 0.5565 - val_accuracy: 0.2000\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5565 - accuracy: 0.2000 - val_loss: 0.5562 - val_accuracy: 0.2000\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5563 - accuracy: 0.2000 - val_loss: 0.5560 - val_accuracy: 0.2000\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5561 - accuracy: 0.2000 - val_loss: 0.5558 - val_accuracy: 0.2000\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5559 - accuracy: 0.2000 - val_loss: 0.5556 - val_accuracy: 0.2000\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5557 - accuracy: 0.2000 - val_loss: 0.5554 - val_accuracy: 0.2000\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5555 - accuracy: 0.2000 - val_loss: 0.5552 - val_accuracy: 0.2000\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5553 - accuracy: 0.2000 - val_loss: 0.5550 - val_accuracy: 0.2000\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5551 - accuracy: 0.2000 - val_loss: 0.5548 - val_accuracy: 0.2000\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5549 - accuracy: 0.2000 - val_loss: 0.5546 - val_accuracy: 0.2000\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5547 - accuracy: 0.2000 - val_loss: 0.5544 - val_accuracy: 0.2000\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5545 - accuracy: 0.2000 - val_loss: 0.5542 - val_accuracy: 0.2000\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5543 - accuracy: 0.2000 - val_loss: 0.5540 - val_accuracy: 0.2000\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5541 - accuracy: 0.2000 - val_loss: 0.5538 - val_accuracy: 0.2000\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5539 - accuracy: 0.2000 - val_loss: 0.5536 - val_accuracy: 0.2000\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.5537 - accuracy: 0.2000 - val_loss: 0.5534 - val_accuracy: 0.2000\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5535 - accuracy: 0.2000 - val_loss: 0.5532 - val_accuracy: 0.2000\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5533 - accuracy: 0.2000 - val_loss: 0.5530 - val_accuracy: 0.2000\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5531 - accuracy: 0.2000 - val_loss: 0.5528 - val_accuracy: 0.2000\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5529 - accuracy: 0.2000 - val_loss: 0.5526 - val_accuracy: 0.2000\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5527 - accuracy: 0.2000 - val_loss: 0.5525 - val_accuracy: 0.2000\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5525 - accuracy: 0.2000 - val_loss: 0.5523 - val_accuracy: 0.2000\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5523 - accuracy: 0.2000 - val_loss: 0.5521 - val_accuracy: 0.2000\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5521 - accuracy: 0.2000 - val_loss: 0.5519 - val_accuracy: 0.2000\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5520 - accuracy: 0.2000 - val_loss: 0.5517 - val_accuracy: 0.2000\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5518 - accuracy: 0.2000 - val_loss: 0.5515 - val_accuracy: 0.2000\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5516 - accuracy: 0.2000 - val_loss: 0.5513 - val_accuracy: 0.2000\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5514 - accuracy: 0.2000 - val_loss: 0.5511 - val_accuracy: 0.2000\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5512 - accuracy: 0.2000 - val_loss: 0.5509 - val_accuracy: 0.2000\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5510 - accuracy: 0.2000 - val_loss: 0.5508 - val_accuracy: 0.2000\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.5508 - accuracy: 0.2000 - val_loss: 0.5506 - val_accuracy: 0.2000\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5506 - accuracy: 0.2000 - val_loss: 0.5504 - val_accuracy: 0.2000\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5505 - accuracy: 0.2000 - val_loss: 0.5502 - val_accuracy: 0.2000\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.5503 - accuracy: 0.2000 - val_loss: 0.5500 - val_accuracy: 0.2000\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5501 - accuracy: 0.2000 - val_loss: 0.5498 - val_accuracy: 0.2000\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5499 - accuracy: 0.2000 - val_loss: 0.5497 - val_accuracy: 0.2000\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5497 - accuracy: 0.2000 - val_loss: 0.5495 - val_accuracy: 0.2000\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5496 - accuracy: 0.2000 - val_loss: 0.5493 - val_accuracy: 0.2000\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5494 - accuracy: 0.2000 - val_loss: 0.5491 - val_accuracy: 0.2000\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5492 - accuracy: 0.2000 - val_loss: 0.5489 - val_accuracy: 0.2000\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5490 - accuracy: 0.2000 - val_loss: 0.5488 - val_accuracy: 0.2000\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5488 - accuracy: 0.2000 - val_loss: 0.5486 - val_accuracy: 0.2000\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5487 - accuracy: 0.2000 - val_loss: 0.5484 - val_accuracy: 0.2000\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5485 - accuracy: 0.2000 - val_loss: 0.5482 - val_accuracy: 0.2000\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5483 - accuracy: 0.2000 - val_loss: 0.5481 - val_accuracy: 0.2000\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5481 - accuracy: 0.2000 - val_loss: 0.5479 - val_accuracy: 0.2000\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5480 - accuracy: 0.2000 - val_loss: 0.5477 - val_accuracy: 0.2000\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5478 - accuracy: 0.2000 - val_loss: 0.5475 - val_accuracy: 0.2000\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5476 - accuracy: 0.2000 - val_loss: 0.5474 - val_accuracy: 0.2000\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 0.5474 - accuracy: 0.2000 - val_loss: 0.5472 - val_accuracy: 0.2000\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5473 - accuracy: 0.2000 - val_loss: 0.5470 - val_accuracy: 0.2000\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5471 - accuracy: 0.2000 - val_loss: 0.5469 - val_accuracy: 0.2000\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.5469 - accuracy: 0.2000 - val_loss: 0.5467 - val_accuracy: 0.2000\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5468 - accuracy: 0.2000 - val_loss: 0.5465 - val_accuracy: 0.2000\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5466 - accuracy: 0.2000 - val_loss: 0.5463 - val_accuracy: 0.2000\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5464 - accuracy: 0.2000 - val_loss: 0.5462 - val_accuracy: 0.2000\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5463 - accuracy: 0.2000 - val_loss: 0.5460 - val_accuracy: 0.2000\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5461 - accuracy: 0.2000 - val_loss: 0.5458 - val_accuracy: 0.2000\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5459 - accuracy: 0.2000 - val_loss: 0.5457 - val_accuracy: 0.2000\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5458 - accuracy: 0.2000 - val_loss: 0.5455 - val_accuracy: 0.2000\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5456 - accuracy: 0.2000 - val_loss: 0.5454 - val_accuracy: 0.2000\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5454 - accuracy: 0.2000 - val_loss: 0.5452 - val_accuracy: 0.2000\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5453 - accuracy: 0.2000 - val_loss: 0.5450 - val_accuracy: 0.2000\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5451 - accuracy: 0.2000 - val_loss: 0.5449 - val_accuracy: 0.2000\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5449 - accuracy: 0.2000 - val_loss: 0.5447 - val_accuracy: 0.2000\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5448 - accuracy: 0.2000 - val_loss: 0.5445 - val_accuracy: 0.2000\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5446 - accuracy: 0.2000 - val_loss: 0.5444 - val_accuracy: 0.2000\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5445 - accuracy: 0.2000 - val_loss: 0.5442 - val_accuracy: 0.2000\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5443 - accuracy: 0.2000 - val_loss: 0.5441 - val_accuracy: 0.2000\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5441 - accuracy: 0.2000 - val_loss: 0.5439 - val_accuracy: 0.2000\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5440 - accuracy: 0.2000 - val_loss: 0.5437 - val_accuracy: 0.2000\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5438 - accuracy: 0.2000 - val_loss: 0.5436 - val_accuracy: 0.2000\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5437 - accuracy: 0.2000 - val_loss: 0.5434 - val_accuracy: 0.2000\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.5435 - accuracy: 0.2000 - val_loss: 0.5433 - val_accuracy: 0.2000\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5434 - accuracy: 0.2000 - val_loss: 0.5431 - val_accuracy: 0.2000\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5432 - accuracy: 0.2000 - val_loss: 0.5430 - val_accuracy: 0.2000\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5430 - accuracy: 0.2000 - val_loss: 0.5428 - val_accuracy: 0.2000\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5429 - accuracy: 0.2000 - val_loss: 0.5427 - val_accuracy: 0.2000\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5427 - accuracy: 0.2000 - val_loss: 0.5425 - val_accuracy: 0.2000\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5426 - accuracy: 0.2000 - val_loss: 0.5424 - val_accuracy: 0.2000\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5424 - accuracy: 0.2000 - val_loss: 0.5422 - val_accuracy: 0.2000\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5423 - accuracy: 0.2000 - val_loss: 0.5421 - val_accuracy: 0.2000\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5421 - accuracy: 0.2000 - val_loss: 0.5419 - val_accuracy: 0.2000\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5420 - accuracy: 0.2000 - val_loss: 0.5418 - val_accuracy: 0.2000\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5418 - accuracy: 0.2000 - val_loss: 0.5416 - val_accuracy: 0.2000\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5417 - accuracy: 0.2000 - val_loss: 0.5415 - val_accuracy: 0.2000\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.5415 - accuracy: 0.2000 - val_loss: 0.5413 - val_accuracy: 0.2000\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5414 - accuracy: 0.2000 - val_loss: 0.5412 - val_accuracy: 0.2000\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5412 - accuracy: 0.2000 - val_loss: 0.5410 - val_accuracy: 0.2000\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5411 - accuracy: 0.2000 - val_loss: 0.5409 - val_accuracy: 0.2000\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5409 - accuracy: 0.2000 - val_loss: 0.5407 - val_accuracy: 0.2000\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5408 - accuracy: 0.2000 - val_loss: 0.5406 - val_accuracy: 0.2000\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5407 - accuracy: 0.2000 - val_loss: 0.5404 - val_accuracy: 0.2000\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5405 - accuracy: 0.2000 - val_loss: 0.5403 - val_accuracy: 0.2000\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5404 - accuracy: 0.2000 - val_loss: 0.5401 - val_accuracy: 0.2000\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5402 - accuracy: 0.2000 - val_loss: 0.5400 - val_accuracy: 0.2000\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5401 - accuracy: 0.2000 - val_loss: 0.5399 - val_accuracy: 0.2000\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5399 - accuracy: 0.2000 - val_loss: 0.5397 - val_accuracy: 0.2000\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.5398 - accuracy: 0.2000 - val_loss: 0.5396 - val_accuracy: 0.2000\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.5397 - accuracy: 0.2000 - val_loss: 0.5394 - val_accuracy: 0.2000\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.5395 - accuracy: 0.2000 - val_loss: 0.5393 - val_accuracy: 0.2000\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5394 - accuracy: 0.2000 - val_loss: 0.5392 - val_accuracy: 0.2000\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5392 - accuracy: 0.2000 - val_loss: 0.5390 - val_accuracy: 0.2000\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5391 - accuracy: 0.2000 - val_loss: 0.5389 - val_accuracy: 0.2000\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5390 - accuracy: 0.2000 - val_loss: 0.5387 - val_accuracy: 0.2000\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5388 - accuracy: 0.2000 - val_loss: 0.5386 - val_accuracy: 0.2000\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5387 - accuracy: 0.2000 - val_loss: 0.5385 - val_accuracy: 0.2000\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5385 - accuracy: 0.2000 - val_loss: 0.5383 - val_accuracy: 0.2000\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5384 - accuracy: 0.2000 - val_loss: 0.5382 - val_accuracy: 0.2000\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5383 - accuracy: 0.2000 - val_loss: 0.5381 - val_accuracy: 0.2000\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5381 - accuracy: 0.2000 - val_loss: 0.5379 - val_accuracy: 0.2000\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5380 - accuracy: 0.2000 - val_loss: 0.5378 - val_accuracy: 0.2000\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5379 - accuracy: 0.2000 - val_loss: 0.5377 - val_accuracy: 0.2000\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5377 - accuracy: 0.2000 - val_loss: 0.5375 - val_accuracy: 0.2000\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5376 - accuracy: 0.2000 - val_loss: 0.5374 - val_accuracy: 0.2000\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5375 - accuracy: 0.2000 - val_loss: 0.5373 - val_accuracy: 0.2000\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5373 - accuracy: 0.2000 - val_loss: 0.5371 - val_accuracy: 0.2000\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.5372 - accuracy: 0.2000 - val_loss: 0.5370 - val_accuracy: 0.2000\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.5371 - accuracy: 0.2000 - val_loss: 0.5369 - val_accuracy: 0.2000\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5369 - accuracy: 0.2000 - val_loss: 0.5367 - val_accuracy: 0.2000\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5368 - accuracy: 0.2000 - val_loss: 0.5366 - val_accuracy: 0.2000\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5367 - accuracy: 0.2000 - val_loss: 0.5365 - val_accuracy: 0.2000\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5366 - accuracy: 0.2000 - val_loss: 0.5363 - val_accuracy: 0.2000\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5364 - accuracy: 0.2000 - val_loss: 0.5362 - val_accuracy: 0.2000\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5363 - accuracy: 0.2000 - val_loss: 0.5361 - val_accuracy: 0.2000\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5362 - accuracy: 0.2000 - val_loss: 0.5360 - val_accuracy: 0.2000\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5360 - accuracy: 0.2000 - val_loss: 0.5358 - val_accuracy: 0.2000\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5359 - accuracy: 0.2000 - val_loss: 0.5357 - val_accuracy: 0.2000\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5358 - accuracy: 0.2000 - val_loss: 0.5356 - val_accuracy: 0.2000\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5357 - accuracy: 0.2000 - val_loss: 0.5355 - val_accuracy: 0.2000\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5355 - accuracy: 0.2000 - val_loss: 0.5353 - val_accuracy: 0.2000\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5354 - accuracy: 0.2000 - val_loss: 0.5352 - val_accuracy: 0.2000\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5353 - accuracy: 0.2000 - val_loss: 0.5351 - val_accuracy: 0.2000\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5352 - accuracy: 0.2000 - val_loss: 0.5350 - val_accuracy: 0.2000\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5350 - accuracy: 0.2000 - val_loss: 0.5348 - val_accuracy: 0.2000\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5349 - accuracy: 0.2000 - val_loss: 0.5347 - val_accuracy: 0.2000\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5348 - accuracy: 0.2000 - val_loss: 0.5346 - val_accuracy: 0.2000\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5347 - accuracy: 0.2000 - val_loss: 0.5345 - val_accuracy: 0.2000\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5345 - accuracy: 0.2000 - val_loss: 0.5344 - val_accuracy: 0.2000\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5344 - accuracy: 0.2000 - val_loss: 0.5342 - val_accuracy: 0.2000\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5343 - accuracy: 0.2000 - val_loss: 0.5341 - val_accuracy: 0.2000\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5342 - accuracy: 0.2000 - val_loss: 0.5340 - val_accuracy: 0.2000\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5341 - accuracy: 0.2000 - val_loss: 0.5339 - val_accuracy: 0.2000\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5339 - accuracy: 0.2000 - val_loss: 0.5338 - val_accuracy: 0.2000\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5338 - accuracy: 0.2000 - val_loss: 0.5336 - val_accuracy: 0.2000\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5337 - accuracy: 0.2000 - val_loss: 0.5335 - val_accuracy: 0.2000\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5336 - accuracy: 0.2000 - val_loss: 0.5334 - val_accuracy: 0.2000\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5335 - accuracy: 0.2000 - val_loss: 0.5333 - val_accuracy: 0.2000\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5334 - accuracy: 0.2000 - val_loss: 0.5332 - val_accuracy: 0.2000\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5332 - accuracy: 0.2000 - val_loss: 0.5331 - val_accuracy: 0.2000\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5331 - accuracy: 0.2000 - val_loss: 0.5329 - val_accuracy: 0.2000\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.5330 - accuracy: 0.2000 - val_loss: 0.5328 - val_accuracy: 0.2000\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5329 - accuracy: 0.2000 - val_loss: 0.5327 - val_accuracy: 0.2000\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5328 - accuracy: 0.2000 - val_loss: 0.5326 - val_accuracy: 0.2000\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5327 - accuracy: 0.2000 - val_loss: 0.5325 - val_accuracy: 0.2000\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5326 - accuracy: 0.2000 - val_loss: 0.5324 - val_accuracy: 0.2000\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5324 - accuracy: 0.2000 - val_loss: 0.5323 - val_accuracy: 0.2000\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5323 - accuracy: 0.2000 - val_loss: 0.5321 - val_accuracy: 0.2000\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.5322 - accuracy: 0.2000 - val_loss: 0.5320 - val_accuracy: 0.2000\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5321 - accuracy: 0.2000 - val_loss: 0.5319 - val_accuracy: 0.2000\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5320 - accuracy: 0.2000 - val_loss: 0.5318 - val_accuracy: 0.2000\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5319 - accuracy: 0.2000 - val_loss: 0.5317 - val_accuracy: 0.2000\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.5318 - accuracy: 0.2000 - val_loss: 0.5316 - val_accuracy: 0.2000\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5317 - accuracy: 0.2000 - val_loss: 0.5315 - val_accuracy: 0.2000\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5316 - accuracy: 0.2000 - val_loss: 0.5314 - val_accuracy: 0.2000\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5314 - accuracy: 0.2000 - val_loss: 0.5313 - val_accuracy: 0.2000\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5313 - accuracy: 0.2000 - val_loss: 0.5311 - val_accuracy: 0.2000\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.5312 - accuracy: 0.2000 - val_loss: 0.5310 - val_accuracy: 0.2000\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5311 - accuracy: 0.2000 - val_loss: 0.5309 - val_accuracy: 0.2000\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5310 - accuracy: 0.2000 - val_loss: 0.5308 - val_accuracy: 0.2000\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5309 - accuracy: 0.2000 - val_loss: 0.5307 - val_accuracy: 0.2000\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5308 - accuracy: 0.2000 - val_loss: 0.5306 - val_accuracy: 0.2000\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5307 - accuracy: 0.2000 - val_loss: 0.5305 - val_accuracy: 0.2000\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5306 - accuracy: 0.2000 - val_loss: 0.5304 - val_accuracy: 0.2000\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5305 - accuracy: 0.2000 - val_loss: 0.5303 - val_accuracy: 0.2000\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5304 - accuracy: 0.2000 - val_loss: 0.5302 - val_accuracy: 0.2000\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5303 - accuracy: 0.2000 - val_loss: 0.5301 - val_accuracy: 0.2000\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.5302 - accuracy: 0.2000 - val_loss: 0.5300 - val_accuracy: 0.2000\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5301 - accuracy: 0.2000 - val_loss: 0.5299 - val_accuracy: 0.2000\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5300 - accuracy: 0.2000 - val_loss: 0.5298 - val_accuracy: 0.2000\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5298 - accuracy: 0.2000 - val_loss: 0.5297 - val_accuracy: 0.2000\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5297 - accuracy: 0.2000 - val_loss: 0.5296 - val_accuracy: 0.2000\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5296 - accuracy: 0.2000 - val_loss: 0.5295 - val_accuracy: 0.2000\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5295 - accuracy: 0.2000 - val_loss: 0.5294 - val_accuracy: 0.2000\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5294 - accuracy: 0.2000 - val_loss: 0.5293 - val_accuracy: 0.2000\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5293 - accuracy: 0.2000 - val_loss: 0.5292 - val_accuracy: 0.2000\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5292 - accuracy: 0.2000 - val_loss: 0.5291 - val_accuracy: 0.2000\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5291 - accuracy: 0.2000 - val_loss: 0.5290 - val_accuracy: 0.2000\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5290 - accuracy: 0.2000 - val_loss: 0.5289 - val_accuracy: 0.2000\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5289 - accuracy: 0.2000 - val_loss: 0.5288 - val_accuracy: 0.2000\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5288 - accuracy: 0.2000 - val_loss: 0.5287 - val_accuracy: 0.2000\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5287 - accuracy: 0.2000 - val_loss: 0.5286 - val_accuracy: 0.2000\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5286 - accuracy: 0.2000 - val_loss: 0.5285 - val_accuracy: 0.2000\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5285 - accuracy: 0.2000 - val_loss: 0.5284 - val_accuracy: 0.2000\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5284 - accuracy: 0.2000 - val_loss: 0.5283 - val_accuracy: 0.2000\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5283 - accuracy: 0.2000 - val_loss: 0.5282 - val_accuracy: 0.2000\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5282 - accuracy: 0.2000 - val_loss: 0.5281 - val_accuracy: 0.2000\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5281 - accuracy: 0.2000 - val_loss: 0.5280 - val_accuracy: 0.2000\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5281 - accuracy: 0.2000 - val_loss: 0.5279 - val_accuracy: 0.2000\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5280 - accuracy: 0.2000 - val_loss: 0.5278 - val_accuracy: 0.2000\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5279 - accuracy: 0.2000 - val_loss: 0.5277 - val_accuracy: 0.2000\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5278 - accuracy: 0.2000 - val_loss: 0.5276 - val_accuracy: 0.2000\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5277 - accuracy: 0.2000 - val_loss: 0.5275 - val_accuracy: 0.2000\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5276 - accuracy: 0.2000 - val_loss: 0.5274 - val_accuracy: 0.2000\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5275 - accuracy: 0.2000 - val_loss: 0.5273 - val_accuracy: 0.2000\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5274 - accuracy: 0.2000 - val_loss: 0.5272 - val_accuracy: 0.2000\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5273 - accuracy: 0.2000 - val_loss: 0.5271 - val_accuracy: 0.2000\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5272 - accuracy: 0.2000 - val_loss: 0.5270 - val_accuracy: 0.2000\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.5271 - accuracy: 0.2000 - val_loss: 0.5269 - val_accuracy: 0.2000\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5270 - accuracy: 0.2000 - val_loss: 0.5268 - val_accuracy: 0.2000\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.5269 - accuracy: 0.2000 - val_loss: 0.5267 - val_accuracy: 0.2000\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5268 - accuracy: 0.2000 - val_loss: 0.5267 - val_accuracy: 0.2000\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5267 - accuracy: 0.2000 - val_loss: 0.5266 - val_accuracy: 0.2000\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5266 - accuracy: 0.2000 - val_loss: 0.5265 - val_accuracy: 0.2000\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5266 - accuracy: 0.2000 - val_loss: 0.5264 - val_accuracy: 0.2000\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5265 - accuracy: 0.2000 - val_loss: 0.5263 - val_accuracy: 0.2000\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5264 - accuracy: 0.2000 - val_loss: 0.5262 - val_accuracy: 0.2000\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5263 - accuracy: 0.2000 - val_loss: 0.5261 - val_accuracy: 0.2000\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5262 - accuracy: 0.2000 - val_loss: 0.5260 - val_accuracy: 0.2000\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5261 - accuracy: 0.2000 - val_loss: 0.5259 - val_accuracy: 0.2000\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5260 - accuracy: 0.2000 - val_loss: 0.5258 - val_accuracy: 0.2000\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5259 - accuracy: 0.2000 - val_loss: 0.5258 - val_accuracy: 0.2000\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5258 - accuracy: 0.2000 - val_loss: 0.5257 - val_accuracy: 0.2000\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5257 - accuracy: 0.2000 - val_loss: 0.5256 - val_accuracy: 0.2000\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5257 - accuracy: 0.2000 - val_loss: 0.5255 - val_accuracy: 0.2000\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5256 - accuracy: 0.2000 - val_loss: 0.5254 - val_accuracy: 0.2000\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5255 - accuracy: 0.2000 - val_loss: 0.5253 - val_accuracy: 0.2000\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5254 - accuracy: 0.2000 - val_loss: 0.5252 - val_accuracy: 0.2000\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5253 - accuracy: 0.2000 - val_loss: 0.5252 - val_accuracy: 0.2000\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5252 - accuracy: 0.2000 - val_loss: 0.5251 - val_accuracy: 0.2000\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5251 - accuracy: 0.2000 - val_loss: 0.5250 - val_accuracy: 0.2000\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5251 - accuracy: 0.2000 - val_loss: 0.5249 - val_accuracy: 0.2000\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5250 - accuracy: 0.2000 - val_loss: 0.5248 - val_accuracy: 0.2000\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5249 - accuracy: 0.2000 - val_loss: 0.5247 - val_accuracy: 0.2000\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5248 - accuracy: 0.2000 - val_loss: 0.5246 - val_accuracy: 0.2000\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5247 - accuracy: 0.2000 - val_loss: 0.5246 - val_accuracy: 0.2000\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5246 - accuracy: 0.2000 - val_loss: 0.5245 - val_accuracy: 0.2000\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5246 - accuracy: 0.2000 - val_loss: 0.5244 - val_accuracy: 0.2000\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5245 - accuracy: 0.2000 - val_loss: 0.5243 - val_accuracy: 0.2000\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5244 - accuracy: 0.2000 - val_loss: 0.5242 - val_accuracy: 0.2000\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5243 - accuracy: 0.2000 - val_loss: 0.5241 - val_accuracy: 0.2000\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.5242 - accuracy: 0.2000 - val_loss: 0.5241 - val_accuracy: 0.2000\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5241 - accuracy: 0.2000 - val_loss: 0.5240 - val_accuracy: 0.2000\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5241 - accuracy: 0.2000 - val_loss: 0.5239 - val_accuracy: 0.2000\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5240 - accuracy: 0.2000 - val_loss: 0.5238 - val_accuracy: 0.2000\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5239 - accuracy: 0.2000 - val_loss: 0.5237 - val_accuracy: 0.2000\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5238 - accuracy: 0.2000 - val_loss: 0.5237 - val_accuracy: 0.2000\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5237 - accuracy: 0.2000 - val_loss: 0.5236 - val_accuracy: 0.2000\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5237 - accuracy: 0.2000 - val_loss: 0.5235 - val_accuracy: 0.2000\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5236 - accuracy: 0.2000 - val_loss: 0.5234 - val_accuracy: 0.2000\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5235 - accuracy: 0.2000 - val_loss: 0.5233 - val_accuracy: 0.2000\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5234 - accuracy: 0.2000 - val_loss: 0.5233 - val_accuracy: 0.2000\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5233 - accuracy: 0.2000 - val_loss: 0.5232 - val_accuracy: 0.2000\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5233 - accuracy: 0.2000 - val_loss: 0.5231 - val_accuracy: 0.2000\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 0.5232 - accuracy: 0.2000 - val_loss: 0.5230 - val_accuracy: 0.2000\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5231 - accuracy: 0.2000 - val_loss: 0.5229 - val_accuracy: 0.2000\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5230 - accuracy: 0.2000 - val_loss: 0.5229 - val_accuracy: 0.2000\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5229 - accuracy: 0.2000 - val_loss: 0.5228 - val_accuracy: 0.2000\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5229 - accuracy: 0.2000 - val_loss: 0.5227 - val_accuracy: 0.2000\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5228 - accuracy: 0.2000 - val_loss: 0.5226 - val_accuracy: 0.2000\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5227 - accuracy: 0.2000 - val_loss: 0.5226 - val_accuracy: 0.2000\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5226 - accuracy: 0.2000 - val_loss: 0.5225 - val_accuracy: 0.2000\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5226 - accuracy: 0.2000 - val_loss: 0.5224 - val_accuracy: 0.2000\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5225 - accuracy: 0.2000 - val_loss: 0.5223 - val_accuracy: 0.2000\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.5224 - accuracy: 0.2000 - val_loss: 0.5223 - val_accuracy: 0.2000\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5223 - accuracy: 0.2000 - val_loss: 0.5222 - val_accuracy: 0.2000\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5223 - accuracy: 0.2000 - val_loss: 0.5221 - val_accuracy: 0.2000\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5222 - accuracy: 0.2000 - val_loss: 0.5220 - val_accuracy: 0.2000\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5221 - accuracy: 0.2000 - val_loss: 0.5220 - val_accuracy: 0.2000\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5220 - accuracy: 0.2000 - val_loss: 0.5219 - val_accuracy: 0.2000\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5220 - accuracy: 0.2000 - val_loss: 0.5218 - val_accuracy: 0.2000\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5219 - accuracy: 0.2000 - val_loss: 0.5217 - val_accuracy: 0.2000\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5218 - accuracy: 0.2000 - val_loss: 0.5217 - val_accuracy: 0.2000\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5217 - accuracy: 0.2000 - val_loss: 0.5216 - val_accuracy: 0.2000\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5217 - accuracy: 0.2000 - val_loss: 0.5215 - val_accuracy: 0.2000\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5216 - accuracy: 0.2000 - val_loss: 0.5214 - val_accuracy: 0.2000\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5215 - accuracy: 0.2000 - val_loss: 0.5214 - val_accuracy: 0.2000\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5215 - accuracy: 0.2000 - val_loss: 0.5213 - val_accuracy: 0.2000\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5214 - accuracy: 0.2000 - val_loss: 0.5212 - val_accuracy: 0.2000\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5213 - accuracy: 0.2000 - val_loss: 0.5212 - val_accuracy: 0.2000\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5212 - accuracy: 0.2000 - val_loss: 0.5211 - val_accuracy: 0.2000\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5212 - accuracy: 0.2000 - val_loss: 0.5210 - val_accuracy: 0.2000\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5211 - accuracy: 0.2000 - val_loss: 0.5209 - val_accuracy: 0.2000\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5210 - accuracy: 0.2000 - val_loss: 0.5209 - val_accuracy: 0.2000\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5210 - accuracy: 0.2000 - val_loss: 0.5208 - val_accuracy: 0.2000\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5209 - accuracy: 0.2000 - val_loss: 0.5207 - val_accuracy: 0.2000\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5208 - accuracy: 0.2000 - val_loss: 0.5207 - val_accuracy: 0.2000\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5207 - accuracy: 0.2000 - val_loss: 0.5206 - val_accuracy: 0.2000\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5207 - accuracy: 0.2000 - val_loss: 0.5205 - val_accuracy: 0.2000\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5206 - accuracy: 0.2000 - val_loss: 0.5205 - val_accuracy: 0.2000\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5205 - accuracy: 0.2000 - val_loss: 0.5204 - val_accuracy: 0.2000\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5205 - accuracy: 0.2000 - val_loss: 0.5203 - val_accuracy: 0.2000\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5204 - accuracy: 0.2000 - val_loss: 0.5203 - val_accuracy: 0.2000\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.5203 - accuracy: 0.2000 - val_loss: 0.5202 - val_accuracy: 0.2000\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5203 - accuracy: 0.2000 - val_loss: 0.5201 - val_accuracy: 0.2000\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5202 - accuracy: 0.2000 - val_loss: 0.5201 - val_accuracy: 0.2000\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5201 - accuracy: 0.2000 - val_loss: 0.5200 - val_accuracy: 0.2000\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5201 - accuracy: 0.2000 - val_loss: 0.5199 - val_accuracy: 0.2000\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5200 - accuracy: 0.2000 - val_loss: 0.5199 - val_accuracy: 0.2000\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5199 - accuracy: 0.2000 - val_loss: 0.5198 - val_accuracy: 0.2000\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5199 - accuracy: 0.2000 - val_loss: 0.5197 - val_accuracy: 0.2000\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5198 - accuracy: 0.2000 - val_loss: 0.5197 - val_accuracy: 0.2000\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5197 - accuracy: 0.2000 - val_loss: 0.5196 - val_accuracy: 0.2000\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5197 - accuracy: 0.2000 - val_loss: 0.5195 - val_accuracy: 0.2000\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5196 - accuracy: 0.2000 - val_loss: 0.5195 - val_accuracy: 0.2000\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5195 - accuracy: 0.2000 - val_loss: 0.5194 - val_accuracy: 0.2000\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5195 - accuracy: 0.2000 - val_loss: 0.5193 - val_accuracy: 0.2000\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5194 - accuracy: 0.2000 - val_loss: 0.5193 - val_accuracy: 0.2000\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5193 - accuracy: 0.2000 - val_loss: 0.5192 - val_accuracy: 0.2000\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5193 - accuracy: 0.2000 - val_loss: 0.5191 - val_accuracy: 0.2000\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5192 - accuracy: 0.2000 - val_loss: 0.5191 - val_accuracy: 0.2000\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5192 - accuracy: 0.2000 - val_loss: 0.5190 - val_accuracy: 0.2000\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5191 - accuracy: 0.2000 - val_loss: 0.5189 - val_accuracy: 0.2000\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5190 - accuracy: 0.2000 - val_loss: 0.5189 - val_accuracy: 0.2000\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5190 - accuracy: 0.2000 - val_loss: 0.5188 - val_accuracy: 0.2000\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5189 - accuracy: 0.2000 - val_loss: 0.5188 - val_accuracy: 0.2000\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5188 - accuracy: 0.2000 - val_loss: 0.5187 - val_accuracy: 0.2000\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.5188 - accuracy: 0.2000 - val_loss: 0.5186 - val_accuracy: 0.2000\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5187 - accuracy: 0.2000 - val_loss: 0.5186 - val_accuracy: 0.2000\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5187 - accuracy: 0.2000 - val_loss: 0.5185 - val_accuracy: 0.2000\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5186 - accuracy: 0.2000 - val_loss: 0.5184 - val_accuracy: 0.2000\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5185 - accuracy: 0.2000 - val_loss: 0.5184 - val_accuracy: 0.2000\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5185 - accuracy: 0.2000 - val_loss: 0.5183 - val_accuracy: 0.2000\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5184 - accuracy: 0.2000 - val_loss: 0.5183 - val_accuracy: 0.2000\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5183 - accuracy: 0.2000 - val_loss: 0.5182 - val_accuracy: 0.2000\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5183 - accuracy: 0.2000 - val_loss: 0.5181 - val_accuracy: 0.2000\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5182 - accuracy: 0.2000 - val_loss: 0.5181 - val_accuracy: 0.2000\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5182 - accuracy: 0.2000 - val_loss: 0.5180 - val_accuracy: 0.2000\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5181 - accuracy: 0.2000 - val_loss: 0.5180 - val_accuracy: 0.2000\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5180 - accuracy: 0.2000 - val_loss: 0.5179 - val_accuracy: 0.2000\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5180 - accuracy: 0.2000 - val_loss: 0.5178 - val_accuracy: 0.2000\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5179 - accuracy: 0.2000 - val_loss: 0.5178 - val_accuracy: 0.2000\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5179 - accuracy: 0.2000 - val_loss: 0.5177 - val_accuracy: 0.2000\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5178 - accuracy: 0.2000 - val_loss: 0.5177 - val_accuracy: 0.2000\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5177 - accuracy: 0.2000 - val_loss: 0.5176 - val_accuracy: 0.2000\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5177 - accuracy: 0.2000 - val_loss: 0.5176 - val_accuracy: 0.2000\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5176 - accuracy: 0.2000 - val_loss: 0.5175 - val_accuracy: 0.2000\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5176 - accuracy: 0.2000 - val_loss: 0.5174 - val_accuracy: 0.2000\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5175 - accuracy: 0.2000 - val_loss: 0.5174 - val_accuracy: 0.2000\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5175 - accuracy: 0.2000 - val_loss: 0.5173 - val_accuracy: 0.2000\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5174 - accuracy: 0.2000 - val_loss: 0.5173 - val_accuracy: 0.2000\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.5173 - accuracy: 0.2000 - val_loss: 0.5172 - val_accuracy: 0.2000\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5173 - accuracy: 0.2000 - val_loss: 0.5172 - val_accuracy: 0.2000\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5172 - accuracy: 0.2000 - val_loss: 0.5171 - val_accuracy: 0.2000\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5172 - accuracy: 0.2000 - val_loss: 0.5170 - val_accuracy: 0.2000\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5171 - accuracy: 0.2000 - val_loss: 0.5170 - val_accuracy: 0.2000\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5171 - accuracy: 0.2000 - val_loss: 0.5169 - val_accuracy: 0.2000\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5170 - accuracy: 0.2000 - val_loss: 0.5169 - val_accuracy: 0.2000\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5170 - accuracy: 0.2000 - val_loss: 0.5168 - val_accuracy: 0.2000\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5169 - accuracy: 0.2000 - val_loss: 0.5168 - val_accuracy: 0.2000\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5168 - accuracy: 0.2000 - val_loss: 0.5167 - val_accuracy: 0.2000\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5168 - accuracy: 0.2000 - val_loss: 0.5167 - val_accuracy: 0.2000\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5167 - accuracy: 0.2000 - val_loss: 0.5166 - val_accuracy: 0.2000\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5167 - accuracy: 0.2000 - val_loss: 0.5165 - val_accuracy: 0.2000\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.5166 - accuracy: 0.2000 - val_loss: 0.5165 - val_accuracy: 0.2000\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5166 - accuracy: 0.2000 - val_loss: 0.5164 - val_accuracy: 0.2000\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5165 - accuracy: 0.2000 - val_loss: 0.5164 - val_accuracy: 0.2000\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5165 - accuracy: 0.2000 - val_loss: 0.5163 - val_accuracy: 0.2000\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5164 - accuracy: 0.2000 - val_loss: 0.5163 - val_accuracy: 0.2000\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5163 - accuracy: 0.2000 - val_loss: 0.5162 - val_accuracy: 0.2000\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5163 - accuracy: 0.2000 - val_loss: 0.5162 - val_accuracy: 0.2000\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5162 - accuracy: 0.2000 - val_loss: 0.5161 - val_accuracy: 0.2000\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5162 - accuracy: 0.2000 - val_loss: 0.5161 - val_accuracy: 0.2000\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5161 - accuracy: 0.2000 - val_loss: 0.5160 - val_accuracy: 0.2000\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.5161 - accuracy: 0.2000 - val_loss: 0.5160 - val_accuracy: 0.2000\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5160 - accuracy: 0.2000 - val_loss: 0.5159 - val_accuracy: 0.2000\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5160 - accuracy: 0.2000 - val_loss: 0.5159 - val_accuracy: 0.2000\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5159 - accuracy: 0.2000 - val_loss: 0.5158 - val_accuracy: 0.2000\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5159 - accuracy: 0.2000 - val_loss: 0.5157 - val_accuracy: 0.2000\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5158 - accuracy: 0.2000 - val_loss: 0.5157 - val_accuracy: 0.2000\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5158 - accuracy: 0.2000 - val_loss: 0.5156 - val_accuracy: 0.2000\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5157 - accuracy: 0.2000 - val_loss: 0.5156 - val_accuracy: 0.2000\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5157 - accuracy: 0.2000 - val_loss: 0.5155 - val_accuracy: 0.2000\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5156 - accuracy: 0.2000 - val_loss: 0.5155 - val_accuracy: 0.2000\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5156 - accuracy: 0.2000 - val_loss: 0.5154 - val_accuracy: 0.2000\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.5155 - accuracy: 0.2000 - val_loss: 0.5154 - val_accuracy: 0.2000\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5155 - accuracy: 0.2000 - val_loss: 0.5153 - val_accuracy: 0.2000\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5154 - accuracy: 0.2000 - val_loss: 0.5153 - val_accuracy: 0.2000\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5154 - accuracy: 0.2000 - val_loss: 0.5152 - val_accuracy: 0.2000\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5153 - accuracy: 0.2000 - val_loss: 0.5152 - val_accuracy: 0.2000\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5153 - accuracy: 0.2000 - val_loss: 0.5151 - val_accuracy: 0.2000\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5152 - accuracy: 0.2000 - val_loss: 0.5151 - val_accuracy: 0.2000\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5152 - accuracy: 0.2000 - val_loss: 0.5150 - val_accuracy: 0.2000\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5151 - accuracy: 0.2000 - val_loss: 0.5150 - val_accuracy: 0.2000\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5151 - accuracy: 0.2000 - val_loss: 0.5149 - val_accuracy: 0.2000\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5150 - accuracy: 0.2000 - val_loss: 0.5149 - val_accuracy: 0.2000\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5150 - accuracy: 0.2000 - val_loss: 0.5148 - val_accuracy: 0.2000\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5149 - accuracy: 0.2000 - val_loss: 0.5148 - val_accuracy: 0.2000\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5149 - accuracy: 0.2000 - val_loss: 0.5148 - val_accuracy: 0.2000\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5148 - accuracy: 0.2000 - val_loss: 0.5147 - val_accuracy: 0.2000\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.5148 - accuracy: 0.2000 - val_loss: 0.5147 - val_accuracy: 0.2000\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5147 - accuracy: 0.2000 - val_loss: 0.5146 - val_accuracy: 0.2000\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5147 - accuracy: 0.2000 - val_loss: 0.5146 - val_accuracy: 0.2000\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5146 - accuracy: 0.2000 - val_loss: 0.5145 - val_accuracy: 0.2000\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5146 - accuracy: 0.2000 - val_loss: 0.5145 - val_accuracy: 0.2000\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5145 - accuracy: 0.2000 - val_loss: 0.5144 - val_accuracy: 0.2000\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5145 - accuracy: 0.2000 - val_loss: 0.5144 - val_accuracy: 0.2000\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5144 - accuracy: 0.2000 - val_loss: 0.5143 - val_accuracy: 0.2000\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5144 - accuracy: 0.2000 - val_loss: 0.5143 - val_accuracy: 0.2000\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5144 - accuracy: 0.2000 - val_loss: 0.5142 - val_accuracy: 0.2000\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5143 - accuracy: 0.2000 - val_loss: 0.5142 - val_accuracy: 0.2000\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5143 - accuracy: 0.2000 - val_loss: 0.5141 - val_accuracy: 0.2000\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5142 - accuracy: 0.2000 - val_loss: 0.5141 - val_accuracy: 0.2000\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5142 - accuracy: 0.2000 - val_loss: 0.5140 - val_accuracy: 0.2000\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5141 - accuracy: 0.2000 - val_loss: 0.5140 - val_accuracy: 0.2000\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5141 - accuracy: 0.2000 - val_loss: 0.5140 - val_accuracy: 0.2000\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5140 - accuracy: 0.2000 - val_loss: 0.5139 - val_accuracy: 0.2000\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5140 - accuracy: 0.2000 - val_loss: 0.5139 - val_accuracy: 0.2000\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.5139 - accuracy: 0.2000 - val_loss: 0.5138 - val_accuracy: 0.2000\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5139 - accuracy: 0.2000 - val_loss: 0.5138 - val_accuracy: 0.2000\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.5139 - accuracy: 0.2000 - val_loss: 0.5137 - val_accuracy: 0.2000\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5138 - accuracy: 0.2000 - val_loss: 0.5137 - val_accuracy: 0.2000\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5138 - accuracy: 0.2000 - val_loss: 0.5136 - val_accuracy: 0.2000\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5137 - accuracy: 0.2000 - val_loss: 0.5136 - val_accuracy: 0.2000\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5137 - accuracy: 0.2000 - val_loss: 0.5136 - val_accuracy: 0.2000\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5136 - accuracy: 0.2000 - val_loss: 0.5135 - val_accuracy: 0.2000\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5136 - accuracy: 0.2000 - val_loss: 0.5135 - val_accuracy: 0.2000\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5135 - accuracy: 0.2000 - val_loss: 0.5134 - val_accuracy: 0.2000\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5135 - accuracy: 0.2000 - val_loss: 0.5134 - val_accuracy: 0.2000\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5135 - accuracy: 0.2000 - val_loss: 0.5133 - val_accuracy: 0.2000\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5134 - accuracy: 0.2000 - val_loss: 0.5133 - val_accuracy: 0.2000\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5134 - accuracy: 0.2000 - val_loss: 0.5133 - val_accuracy: 0.2000\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5133 - accuracy: 0.2000 - val_loss: 0.5132 - val_accuracy: 0.2000\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5133 - accuracy: 0.2000 - val_loss: 0.5132 - val_accuracy: 0.2000\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5132 - accuracy: 0.2000 - val_loss: 0.5131 - val_accuracy: 0.2000\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5132 - accuracy: 0.2000 - val_loss: 0.5131 - val_accuracy: 0.2000\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5132 - accuracy: 0.2000 - val_loss: 0.5130 - val_accuracy: 0.2000\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5131 - accuracy: 0.2000 - val_loss: 0.5130 - val_accuracy: 0.2000\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5131 - accuracy: 0.2000 - val_loss: 0.5130 - val_accuracy: 0.2000\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5130 - accuracy: 0.2000 - val_loss: 0.5129 - val_accuracy: 0.2000\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 422ms/step - loss: 0.5130 - accuracy: 0.2000 - val_loss: 0.5129 - val_accuracy: 0.2000\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5129 - accuracy: 0.2000 - val_loss: 0.5128 - val_accuracy: 0.2000\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5129 - accuracy: 0.2000 - val_loss: 0.5128 - val_accuracy: 0.2000\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5129 - accuracy: 0.2000 - val_loss: 0.5127 - val_accuracy: 0.2000\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5128 - accuracy: 0.2000 - val_loss: 0.5127 - val_accuracy: 0.2000\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5128 - accuracy: 0.2000 - val_loss: 0.5127 - val_accuracy: 0.2000\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5127 - accuracy: 0.2000 - val_loss: 0.5126 - val_accuracy: 0.2000\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5127 - accuracy: 0.2000 - val_loss: 0.5126 - val_accuracy: 0.2000\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5127 - accuracy: 0.2000 - val_loss: 0.5125 - val_accuracy: 0.2000\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5126 - accuracy: 0.2000 - val_loss: 0.5125 - val_accuracy: 0.2000\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5126 - accuracy: 0.2000 - val_loss: 0.5125 - val_accuracy: 0.2000\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5125 - accuracy: 0.2000 - val_loss: 0.5124 - val_accuracy: 0.2000\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5125 - accuracy: 0.2000 - val_loss: 0.5124 - val_accuracy: 0.2000\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5125 - accuracy: 0.2000 - val_loss: 0.5123 - val_accuracy: 0.2000\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5124 - accuracy: 0.2000 - val_loss: 0.5123 - val_accuracy: 0.2000\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5124 - accuracy: 0.2000 - val_loss: 0.5123 - val_accuracy: 0.2000\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5123 - accuracy: 0.2000 - val_loss: 0.5122 - val_accuracy: 0.2000\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5123 - accuracy: 0.2000 - val_loss: 0.5122 - val_accuracy: 0.2000\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5123 - accuracy: 0.2000 - val_loss: 0.5121 - val_accuracy: 0.2000\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.5122 - accuracy: 0.2000 - val_loss: 0.5121 - val_accuracy: 0.2000\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5122 - accuracy: 0.2000 - val_loss: 0.5121 - val_accuracy: 0.2000\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 0.5121 - accuracy: 0.2000 - val_loss: 0.5120 - val_accuracy: 0.2000\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5121 - accuracy: 0.2000 - val_loss: 0.5120 - val_accuracy: 0.2000\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5121 - accuracy: 0.2000 - val_loss: 0.5120 - val_accuracy: 0.2000\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5120 - accuracy: 0.2000 - val_loss: 0.5119 - val_accuracy: 0.2000\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5120 - accuracy: 0.2000 - val_loss: 0.5119 - val_accuracy: 0.2000\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5120 - accuracy: 0.2000 - val_loss: 0.5118 - val_accuracy: 0.2000\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5119 - accuracy: 0.2000 - val_loss: 0.5118 - val_accuracy: 0.2000\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5119 - accuracy: 0.2000 - val_loss: 0.5118 - val_accuracy: 0.2000\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 0.5118 - accuracy: 0.2000 - val_loss: 0.5117 - val_accuracy: 0.2000\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5118 - accuracy: 0.2000 - val_loss: 0.5117 - val_accuracy: 0.2000\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5118 - accuracy: 0.2000 - val_loss: 0.5117 - val_accuracy: 0.2000\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5117 - accuracy: 0.2000 - val_loss: 0.5116 - val_accuracy: 0.2000\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5117 - accuracy: 0.2000 - val_loss: 0.5116 - val_accuracy: 0.2000\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5117 - accuracy: 0.2000 - val_loss: 0.5115 - val_accuracy: 0.2000\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5116 - accuracy: 0.2000 - val_loss: 0.5115 - val_accuracy: 0.2000\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5116 - accuracy: 0.2000 - val_loss: 0.5115 - val_accuracy: 0.2000\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5115 - accuracy: 0.2000 - val_loss: 0.5114 - val_accuracy: 0.2000\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5115 - accuracy: 0.2000 - val_loss: 0.5114 - val_accuracy: 0.2000\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.5115 - accuracy: 0.2000 - val_loss: 0.5114 - val_accuracy: 0.2000\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5114 - accuracy: 0.2000 - val_loss: 0.5113 - val_accuracy: 0.2000\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5114 - accuracy: 0.2000 - val_loss: 0.5113 - val_accuracy: 0.2000\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5114 - accuracy: 0.2000 - val_loss: 0.5113 - val_accuracy: 0.2000\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5113 - accuracy: 0.2000 - val_loss: 0.5112 - val_accuracy: 0.2000\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5113 - accuracy: 0.2000 - val_loss: 0.5112 - val_accuracy: 0.2000\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5113 - accuracy: 0.2000 - val_loss: 0.5111 - val_accuracy: 0.2000\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5112 - accuracy: 0.2000 - val_loss: 0.5111 - val_accuracy: 0.2000\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5112 - accuracy: 0.2000 - val_loss: 0.5111 - val_accuracy: 0.2000\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5111 - accuracy: 0.2000 - val_loss: 0.5110 - val_accuracy: 0.2000\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5111 - accuracy: 0.2000 - val_loss: 0.5110 - val_accuracy: 0.2000\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5111 - accuracy: 0.2000 - val_loss: 0.5110 - val_accuracy: 0.2000\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5110 - accuracy: 0.2000 - val_loss: 0.5109 - val_accuracy: 0.2000\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5110 - accuracy: 0.2000 - val_loss: 0.5109 - val_accuracy: 0.2000\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5110 - accuracy: 0.2000 - val_loss: 0.5109 - val_accuracy: 0.2000\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5109 - accuracy: 0.2000 - val_loss: 0.5108 - val_accuracy: 0.2000\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5109 - accuracy: 0.2000 - val_loss: 0.5108 - val_accuracy: 0.2000\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5109 - accuracy: 0.2000 - val_loss: 0.5108 - val_accuracy: 0.2000\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5108 - accuracy: 0.2000 - val_loss: 0.5107 - val_accuracy: 0.2000\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.5108 - accuracy: 0.2000 - val_loss: 0.5107 - val_accuracy: 0.2000\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5108 - accuracy: 0.2000 - val_loss: 0.5107 - val_accuracy: 0.2000\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5107 - accuracy: 0.2000 - val_loss: 0.5106 - val_accuracy: 0.2000\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5107 - accuracy: 0.2000 - val_loss: 0.5106 - val_accuracy: 0.2000\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5107 - accuracy: 0.2000 - val_loss: 0.5106 - val_accuracy: 0.2000\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5106 - accuracy: 0.2000 - val_loss: 0.5105 - val_accuracy: 0.2000\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5106 - accuracy: 0.2000 - val_loss: 0.5105 - val_accuracy: 0.2000\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5106 - accuracy: 0.2000 - val_loss: 0.5105 - val_accuracy: 0.2000\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5105 - accuracy: 0.2000 - val_loss: 0.5104 - val_accuracy: 0.2000\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5105 - accuracy: 0.2000 - val_loss: 0.5104 - val_accuracy: 0.2000\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5105 - accuracy: 0.2000 - val_loss: 0.5104 - val_accuracy: 0.2000\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5104 - accuracy: 0.2000 - val_loss: 0.5103 - val_accuracy: 0.2000\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5104 - accuracy: 0.2000 - val_loss: 0.5103 - val_accuracy: 0.2000\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5104 - accuracy: 0.2000 - val_loss: 0.5103 - val_accuracy: 0.2000\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5103 - accuracy: 0.2000 - val_loss: 0.5102 - val_accuracy: 0.2000\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5103 - accuracy: 0.2000 - val_loss: 0.5102 - val_accuracy: 0.2000\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5103 - accuracy: 0.2000 - val_loss: 0.5102 - val_accuracy: 0.2000\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5102 - accuracy: 0.2000 - val_loss: 0.5101 - val_accuracy: 0.2000\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5102 - accuracy: 0.2000 - val_loss: 0.5101 - val_accuracy: 0.2000\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.5102 - accuracy: 0.2000 - val_loss: 0.5101 - val_accuracy: 0.2000\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5101 - accuracy: 0.2000 - val_loss: 0.5100 - val_accuracy: 0.2000\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5101 - accuracy: 0.2000 - val_loss: 0.5100 - val_accuracy: 0.2000\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5101 - accuracy: 0.2000 - val_loss: 0.5100 - val_accuracy: 0.2000\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5100 - accuracy: 0.2000 - val_loss: 0.5099 - val_accuracy: 0.2000\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5100 - accuracy: 0.2000 - val_loss: 0.5099 - val_accuracy: 0.2000\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5100 - accuracy: 0.2000 - val_loss: 0.5099 - val_accuracy: 0.2000\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5100 - accuracy: 0.2000 - val_loss: 0.5098 - val_accuracy: 0.2000\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.5099 - accuracy: 0.2000 - val_loss: 0.5098 - val_accuracy: 0.2000\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5099 - accuracy: 0.2000 - val_loss: 0.5098 - val_accuracy: 0.2000\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5099 - accuracy: 0.2000 - val_loss: 0.5098 - val_accuracy: 0.2000\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5098 - accuracy: 0.2000 - val_loss: 0.5097 - val_accuracy: 0.2000\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5098 - accuracy: 0.2000 - val_loss: 0.5097 - val_accuracy: 0.2000\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5098 - accuracy: 0.2000 - val_loss: 0.5097 - val_accuracy: 0.2000\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5097 - accuracy: 0.2000 - val_loss: 0.5096 - val_accuracy: 0.2000\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5097 - accuracy: 0.2000 - val_loss: 0.5096 - val_accuracy: 0.2000\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5097 - accuracy: 0.2000 - val_loss: 0.5096 - val_accuracy: 0.2000\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5096 - accuracy: 0.2000 - val_loss: 0.5095 - val_accuracy: 0.2000\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5096 - accuracy: 0.2000 - val_loss: 0.5095 - val_accuracy: 0.2000\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.5096 - accuracy: 0.2000 - val_loss: 0.5095 - val_accuracy: 0.2000\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5096 - accuracy: 0.2000 - val_loss: 0.5095 - val_accuracy: 0.2000\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5095 - accuracy: 0.2000 - val_loss: 0.5094 - val_accuracy: 0.2000\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5095 - accuracy: 0.2000 - val_loss: 0.5094 - val_accuracy: 0.2000\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5095 - accuracy: 0.2000 - val_loss: 0.5094 - val_accuracy: 0.2000\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5094 - accuracy: 0.2000 - val_loss: 0.5093 - val_accuracy: 0.2000\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5094 - accuracy: 0.2000 - val_loss: 0.5093 - val_accuracy: 0.2000\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5094 - accuracy: 0.2000 - val_loss: 0.5093 - val_accuracy: 0.2000\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5094 - accuracy: 0.2000 - val_loss: 0.5092 - val_accuracy: 0.2000\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5093 - accuracy: 0.2000 - val_loss: 0.5092 - val_accuracy: 0.2000\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5093 - accuracy: 0.2000 - val_loss: 0.5092 - val_accuracy: 0.2000\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5093 - accuracy: 0.2000 - val_loss: 0.5092 - val_accuracy: 0.2000\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5092 - accuracy: 0.2000 - val_loss: 0.5091 - val_accuracy: 0.2000\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5092 - accuracy: 0.2000 - val_loss: 0.5091 - val_accuracy: 0.2000\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5092 - accuracy: 0.2000 - val_loss: 0.5091 - val_accuracy: 0.2000\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5091 - accuracy: 0.2000 - val_loss: 0.5090 - val_accuracy: 0.2000\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5091 - accuracy: 0.2000 - val_loss: 0.5090 - val_accuracy: 0.2000\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5091 - accuracy: 0.2000 - val_loss: 0.5090 - val_accuracy: 0.2000\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.5091 - accuracy: 0.2000 - val_loss: 0.5090 - val_accuracy: 0.2000\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5090 - accuracy: 0.2000 - val_loss: 0.5089 - val_accuracy: 0.2000\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5090 - accuracy: 0.2000 - val_loss: 0.5089 - val_accuracy: 0.2000\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5090 - accuracy: 0.2000 - val_loss: 0.5089 - val_accuracy: 0.2000\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5090 - accuracy: 0.2000 - val_loss: 0.5088 - val_accuracy: 0.2000\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5089 - accuracy: 0.2000 - val_loss: 0.5088 - val_accuracy: 0.2000\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5089 - accuracy: 0.2000 - val_loss: 0.5088 - val_accuracy: 0.2000\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5089 - accuracy: 0.2000 - val_loss: 0.5088 - val_accuracy: 0.2000\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5088 - accuracy: 0.2000 - val_loss: 0.5087 - val_accuracy: 0.2000\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5088 - accuracy: 0.2000 - val_loss: 0.5087 - val_accuracy: 0.2000\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5088 - accuracy: 0.2000 - val_loss: 0.5087 - val_accuracy: 0.2000\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.5088 - accuracy: 0.2000 - val_loss: 0.5087 - val_accuracy: 0.2000\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5087 - accuracy: 0.2000 - val_loss: 0.5086 - val_accuracy: 0.2000\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5087 - accuracy: 0.2000 - val_loss: 0.5086 - val_accuracy: 0.2000\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5087 - accuracy: 0.2000 - val_loss: 0.5086 - val_accuracy: 0.2000\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5087 - accuracy: 0.2000 - val_loss: 0.5085 - val_accuracy: 0.2000\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5086 - accuracy: 0.2000 - val_loss: 0.5085 - val_accuracy: 0.2000\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 410ms/step - loss: 0.5086 - accuracy: 0.2000 - val_loss: 0.5085 - val_accuracy: 0.2000\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5086 - accuracy: 0.2000 - val_loss: 0.5085 - val_accuracy: 0.2000\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5085 - accuracy: 0.2000 - val_loss: 0.5084 - val_accuracy: 0.2000\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5085 - accuracy: 0.2000 - val_loss: 0.5084 - val_accuracy: 0.2000\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5085 - accuracy: 0.2000 - val_loss: 0.5084 - val_accuracy: 0.2000\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5085 - accuracy: 0.2000 - val_loss: 0.5084 - val_accuracy: 0.2000\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5084 - accuracy: 0.2000 - val_loss: 0.5083 - val_accuracy: 0.2000\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5084 - accuracy: 0.2000 - val_loss: 0.5083 - val_accuracy: 0.2000\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5084 - accuracy: 0.2000 - val_loss: 0.5083 - val_accuracy: 0.2000\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5084 - accuracy: 0.2000 - val_loss: 0.5083 - val_accuracy: 0.2000\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5083 - accuracy: 0.2000 - val_loss: 0.5082 - val_accuracy: 0.2000\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5083 - accuracy: 0.2000 - val_loss: 0.5082 - val_accuracy: 0.2000\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5083 - accuracy: 0.2000 - val_loss: 0.5082 - val_accuracy: 0.2000\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5083 - accuracy: 0.2000 - val_loss: 0.5082 - val_accuracy: 0.2000\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5082 - accuracy: 0.2000 - val_loss: 0.5081 - val_accuracy: 0.2000\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5082 - accuracy: 0.2000 - val_loss: 0.5081 - val_accuracy: 0.2000\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.5082 - accuracy: 0.2000 - val_loss: 0.5081 - val_accuracy: 0.2000\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 0.5082 - accuracy: 0.2000 - val_loss: 0.5081 - val_accuracy: 0.2000\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5081 - accuracy: 0.2000 - val_loss: 0.5080 - val_accuracy: 0.2000\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5081 - accuracy: 0.2000 - val_loss: 0.5080 - val_accuracy: 0.2000\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5081 - accuracy: 0.2000 - val_loss: 0.5080 - val_accuracy: 0.2000\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5081 - accuracy: 0.2000 - val_loss: 0.5080 - val_accuracy: 0.2000\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5080 - accuracy: 0.2000 - val_loss: 0.5079 - val_accuracy: 0.2000\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5080 - accuracy: 0.2000 - val_loss: 0.5079 - val_accuracy: 0.2000\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5080 - accuracy: 0.2000 - val_loss: 0.5079 - val_accuracy: 0.2000\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5080 - accuracy: 0.2000 - val_loss: 0.5079 - val_accuracy: 0.2000\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5079 - accuracy: 0.2000 - val_loss: 0.5078 - val_accuracy: 0.2000\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5079 - accuracy: 0.2000 - val_loss: 0.5078 - val_accuracy: 0.2000\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5079 - accuracy: 0.2000 - val_loss: 0.5078 - val_accuracy: 0.2000\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5079 - accuracy: 0.2000 - val_loss: 0.5078 - val_accuracy: 0.2000\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5078 - accuracy: 0.2000 - val_loss: 0.5077 - val_accuracy: 0.2000\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5078 - accuracy: 0.2000 - val_loss: 0.5077 - val_accuracy: 0.2000\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5078 - accuracy: 0.2000 - val_loss: 0.5077 - val_accuracy: 0.2000\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5078 - accuracy: 0.2000 - val_loss: 0.5077 - val_accuracy: 0.2000\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5077 - accuracy: 0.2000 - val_loss: 0.5076 - val_accuracy: 0.2000\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.5077 - accuracy: 0.2000 - val_loss: 0.5076 - val_accuracy: 0.2000\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5077 - accuracy: 0.2000 - val_loss: 0.5076 - val_accuracy: 0.2000\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5077 - accuracy: 0.2000 - val_loss: 0.5076 - val_accuracy: 0.2000\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5076 - accuracy: 0.2000 - val_loss: 0.5075 - val_accuracy: 0.2000\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5076 - accuracy: 0.2000 - val_loss: 0.5075 - val_accuracy: 0.2000\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5076 - accuracy: 0.2000 - val_loss: 0.5075 - val_accuracy: 0.2000\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5076 - accuracy: 0.2000 - val_loss: 0.5075 - val_accuracy: 0.2000\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5076 - accuracy: 0.2000 - val_loss: 0.5075 - val_accuracy: 0.2000\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5075 - accuracy: 0.2000 - val_loss: 0.5074 - val_accuracy: 0.2000\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5075 - accuracy: 0.2000 - val_loss: 0.5074 - val_accuracy: 0.2000\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5075 - accuracy: 0.2000 - val_loss: 0.5074 - val_accuracy: 0.2000\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5075 - accuracy: 0.2000 - val_loss: 0.5074 - val_accuracy: 0.2000\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5074 - accuracy: 0.2000 - val_loss: 0.5073 - val_accuracy: 0.2000\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5074 - accuracy: 0.2000 - val_loss: 0.5073 - val_accuracy: 0.2000\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5074 - accuracy: 0.2000 - val_loss: 0.5073 - val_accuracy: 0.2000\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.5074 - accuracy: 0.2000 - val_loss: 0.5073 - val_accuracy: 0.2000\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5073 - accuracy: 0.2000 - val_loss: 0.5073 - val_accuracy: 0.2000\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5073 - accuracy: 0.2000 - val_loss: 0.5072 - val_accuracy: 0.2000\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5073 - accuracy: 0.2000 - val_loss: 0.5072 - val_accuracy: 0.2000\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5073 - accuracy: 0.2000 - val_loss: 0.5072 - val_accuracy: 0.2000\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5073 - accuracy: 0.2000 - val_loss: 0.5072 - val_accuracy: 0.2000\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5072 - accuracy: 0.2000 - val_loss: 0.5071 - val_accuracy: 0.2000\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5072 - accuracy: 0.2000 - val_loss: 0.5071 - val_accuracy: 0.2000\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5072 - accuracy: 0.2000 - val_loss: 0.5071 - val_accuracy: 0.2000\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5072 - accuracy: 0.2000 - val_loss: 0.5071 - val_accuracy: 0.2000\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5072 - accuracy: 0.2000 - val_loss: 0.5071 - val_accuracy: 0.2000\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5071 - accuracy: 0.2000 - val_loss: 0.5070 - val_accuracy: 0.2000\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5071 - accuracy: 0.2000 - val_loss: 0.5070 - val_accuracy: 0.2000\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5071 - accuracy: 0.2000 - val_loss: 0.5070 - val_accuracy: 0.2000\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5071 - accuracy: 0.2000 - val_loss: 0.5070 - val_accuracy: 0.2000\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.5070 - accuracy: 0.2000 - val_loss: 0.5069 - val_accuracy: 0.2000\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.5070 - accuracy: 0.2000 - val_loss: 0.5069 - val_accuracy: 0.2000\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5070 - accuracy: 0.2000 - val_loss: 0.5069 - val_accuracy: 0.2000\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5070 - accuracy: 0.2000 - val_loss: 0.5069 - val_accuracy: 0.2000\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5070 - accuracy: 0.2000 - val_loss: 0.5069 - val_accuracy: 0.2000\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5069 - accuracy: 0.2000 - val_loss: 0.5068 - val_accuracy: 0.2000\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5069 - accuracy: 0.2000 - val_loss: 0.5068 - val_accuracy: 0.2000\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5069 - accuracy: 0.2000 - val_loss: 0.5068 - val_accuracy: 0.2000\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5069 - accuracy: 0.2000 - val_loss: 0.5068 - val_accuracy: 0.2000\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5069 - accuracy: 0.2000 - val_loss: 0.5068 - val_accuracy: 0.2000\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5068 - accuracy: 0.2000 - val_loss: 0.5067 - val_accuracy: 0.2000\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5068 - accuracy: 0.2000 - val_loss: 0.5067 - val_accuracy: 0.2000\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5068 - accuracy: 0.2000 - val_loss: 0.5067 - val_accuracy: 0.2000\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5068 - accuracy: 0.2000 - val_loss: 0.5067 - val_accuracy: 0.2000\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5067 - accuracy: 0.2000 - val_loss: 0.5067 - val_accuracy: 0.2000\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.5067 - accuracy: 0.2000 - val_loss: 0.5066 - val_accuracy: 0.2000\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5067 - accuracy: 0.2000 - val_loss: 0.5066 - val_accuracy: 0.2000\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5067 - accuracy: 0.2000 - val_loss: 0.5066 - val_accuracy: 0.2000\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5067 - accuracy: 0.2000 - val_loss: 0.5066 - val_accuracy: 0.2000\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5066 - accuracy: 0.2000 - val_loss: 0.5066 - val_accuracy: 0.2000\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5066 - accuracy: 0.2000 - val_loss: 0.5065 - val_accuracy: 0.2000\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5066 - accuracy: 0.2000 - val_loss: 0.5065 - val_accuracy: 0.2000\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5066 - accuracy: 0.2000 - val_loss: 0.5065 - val_accuracy: 0.2000\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5066 - accuracy: 0.2000 - val_loss: 0.5065 - val_accuracy: 0.2000\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5065 - accuracy: 0.2000 - val_loss: 0.5065 - val_accuracy: 0.2000\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5065 - accuracy: 0.2000 - val_loss: 0.5064 - val_accuracy: 0.2000\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5065 - accuracy: 0.2000 - val_loss: 0.5064 - val_accuracy: 0.2000\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5065 - accuracy: 0.2000 - val_loss: 0.5064 - val_accuracy: 0.2000\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5065 - accuracy: 0.2000 - val_loss: 0.5064 - val_accuracy: 0.2000\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.5064 - accuracy: 0.2000 - val_loss: 0.5064 - val_accuracy: 0.2000\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 409ms/step - loss: 0.5064 - accuracy: 0.2000 - val_loss: 0.5063 - val_accuracy: 0.2000\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5064 - accuracy: 0.2000 - val_loss: 0.5063 - val_accuracy: 0.2000\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5064 - accuracy: 0.2000 - val_loss: 0.5063 - val_accuracy: 0.2000\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.5064 - accuracy: 0.2000 - val_loss: 0.5063 - val_accuracy: 0.2000\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5064 - accuracy: 0.2000 - val_loss: 0.5063 - val_accuracy: 0.2000\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5063 - accuracy: 0.2000 - val_loss: 0.5062 - val_accuracy: 0.2000\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5063 - accuracy: 0.2000 - val_loss: 0.5062 - val_accuracy: 0.2000\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5063 - accuracy: 0.2000 - val_loss: 0.5062 - val_accuracy: 0.2000\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5063 - accuracy: 0.2000 - val_loss: 0.5062 - val_accuracy: 0.2000\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5063 - accuracy: 0.2000 - val_loss: 0.5062 - val_accuracy: 0.2000\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5062 - accuracy: 0.2000 - val_loss: 0.5061 - val_accuracy: 0.2000\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5062 - accuracy: 0.2000 - val_loss: 0.5061 - val_accuracy: 0.2000\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5062 - accuracy: 0.2000 - val_loss: 0.5061 - val_accuracy: 0.2000\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5062 - accuracy: 0.2000 - val_loss: 0.5061 - val_accuracy: 0.2000\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5062 - accuracy: 0.2000 - val_loss: 0.5061 - val_accuracy: 0.2000\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.5061 - accuracy: 0.2000 - val_loss: 0.5060 - val_accuracy: 0.2000\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5061 - accuracy: 0.2000 - val_loss: 0.5060 - val_accuracy: 0.2000\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5061 - accuracy: 0.2000 - val_loss: 0.5060 - val_accuracy: 0.2000\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5061 - accuracy: 0.2000 - val_loss: 0.5060 - val_accuracy: 0.2000\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5061 - accuracy: 0.2000 - val_loss: 0.5060 - val_accuracy: 0.2000\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5061 - accuracy: 0.2000 - val_loss: 0.5060 - val_accuracy: 0.2000\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5060 - accuracy: 0.2000 - val_loss: 0.5059 - val_accuracy: 0.2000\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5060 - accuracy: 0.2000 - val_loss: 0.5059 - val_accuracy: 0.2000\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5060 - accuracy: 0.2000 - val_loss: 0.5059 - val_accuracy: 0.2000\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5060 - accuracy: 0.2000 - val_loss: 0.5059 - val_accuracy: 0.2000\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5060 - accuracy: 0.2000 - val_loss: 0.5059 - val_accuracy: 0.2000\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5059 - accuracy: 0.2000 - val_loss: 0.5059 - val_accuracy: 0.2000\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5059 - accuracy: 0.2000 - val_loss: 0.5058 - val_accuracy: 0.2000\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5059 - accuracy: 0.2000 - val_loss: 0.5058 - val_accuracy: 0.2000\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5059 - accuracy: 0.2000 - val_loss: 0.5058 - val_accuracy: 0.2000\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.5059 - accuracy: 0.2000 - val_loss: 0.5058 - val_accuracy: 0.2000\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.5059 - accuracy: 0.2000 - val_loss: 0.5058 - val_accuracy: 0.2000\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5058 - accuracy: 0.2000 - val_loss: 0.5057 - val_accuracy: 0.2000\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5058 - accuracy: 0.2000 - val_loss: 0.5057 - val_accuracy: 0.2000\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5058 - accuracy: 0.2000 - val_loss: 0.5057 - val_accuracy: 0.2000\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5058 - accuracy: 0.2000 - val_loss: 0.5057 - val_accuracy: 0.2000\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5058 - accuracy: 0.2000 - val_loss: 0.5057 - val_accuracy: 0.2000\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5058 - accuracy: 0.2000 - val_loss: 0.5057 - val_accuracy: 0.2000\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5057 - accuracy: 0.2000 - val_loss: 0.5056 - val_accuracy: 0.2000\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5057 - accuracy: 0.2000 - val_loss: 0.5056 - val_accuracy: 0.2000\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5057 - accuracy: 0.2000 - val_loss: 0.5056 - val_accuracy: 0.2000\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5057 - accuracy: 0.2000 - val_loss: 0.5056 - val_accuracy: 0.2000\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5057 - accuracy: 0.2000 - val_loss: 0.5056 - val_accuracy: 0.2000\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5056 - accuracy: 0.2000 - val_loss: 0.5056 - val_accuracy: 0.2000\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5056 - accuracy: 0.2000 - val_loss: 0.5055 - val_accuracy: 0.2000\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5056 - accuracy: 0.2000 - val_loss: 0.5055 - val_accuracy: 0.2000\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5056 - accuracy: 0.2000 - val_loss: 0.5055 - val_accuracy: 0.2000\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5056 - accuracy: 0.2000 - val_loss: 0.5055 - val_accuracy: 0.2000\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.5056 - accuracy: 0.2000 - val_loss: 0.5055 - val_accuracy: 0.2000\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5055 - accuracy: 0.2000 - val_loss: 0.5055 - val_accuracy: 0.2000\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5055 - accuracy: 0.2000 - val_loss: 0.5054 - val_accuracy: 0.2000\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.5055 - accuracy: 0.2000 - val_loss: 0.5054 - val_accuracy: 0.2000\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5055 - accuracy: 0.2000 - val_loss: 0.5054 - val_accuracy: 0.2000\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5055 - accuracy: 0.2000 - val_loss: 0.5054 - val_accuracy: 0.2000\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5055 - accuracy: 0.2000 - val_loss: 0.5054 - val_accuracy: 0.2000\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5055 - accuracy: 0.2000 - val_loss: 0.5054 - val_accuracy: 0.2000\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5054 - accuracy: 0.2000 - val_loss: 0.5053 - val_accuracy: 0.2000\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5054 - accuracy: 0.2000 - val_loss: 0.5053 - val_accuracy: 0.2000\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 0.5054 - accuracy: 0.2000 - val_loss: 0.5053 - val_accuracy: 0.2000\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.5054 - accuracy: 0.2000 - val_loss: 0.5053 - val_accuracy: 0.2000\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5054 - accuracy: 0.2000 - val_loss: 0.5053 - val_accuracy: 0.2000\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5054 - accuracy: 0.2000 - val_loss: 0.5053 - val_accuracy: 0.2000\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5053 - accuracy: 0.2000 - val_loss: 0.5052 - val_accuracy: 0.2000\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5053 - accuracy: 0.2000 - val_loss: 0.5052 - val_accuracy: 0.2000\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5053 - accuracy: 0.2000 - val_loss: 0.5052 - val_accuracy: 0.2000\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5053 - accuracy: 0.2000 - val_loss: 0.5052 - val_accuracy: 0.2000\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5053 - accuracy: 0.2000 - val_loss: 0.5052 - val_accuracy: 0.2000\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5053 - accuracy: 0.2000 - val_loss: 0.5052 - val_accuracy: 0.2000\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5052 - accuracy: 0.2000 - val_loss: 0.5052 - val_accuracy: 0.2000\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5052 - accuracy: 0.2000 - val_loss: 0.5051 - val_accuracy: 0.2000\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.5052 - accuracy: 0.2000 - val_loss: 0.5051 - val_accuracy: 0.2000\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 0.5052 - accuracy: 0.2000 - val_loss: 0.5051 - val_accuracy: 0.2000\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5052 - accuracy: 0.2000 - val_loss: 0.5051 - val_accuracy: 0.2000\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5052 - accuracy: 0.2000 - val_loss: 0.5051 - val_accuracy: 0.2000\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5052 - accuracy: 0.2000 - val_loss: 0.5051 - val_accuracy: 0.2000\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5051 - accuracy: 0.2000 - val_loss: 0.5050 - val_accuracy: 0.2000\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5051 - accuracy: 0.2000 - val_loss: 0.5050 - val_accuracy: 0.2000\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.5051 - accuracy: 0.2000 - val_loss: 0.5050 - val_accuracy: 0.2000\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5051 - accuracy: 0.2000 - val_loss: 0.5050 - val_accuracy: 0.2000\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5051 - accuracy: 0.2000 - val_loss: 0.5050 - val_accuracy: 0.2000\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5051 - accuracy: 0.2000 - val_loss: 0.5050 - val_accuracy: 0.2000\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5050 - accuracy: 0.2000 - val_loss: 0.5050 - val_accuracy: 0.2000\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5050 - accuracy: 0.2000 - val_loss: 0.5049 - val_accuracy: 0.2000\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.5050 - accuracy: 0.2000 - val_loss: 0.5049 - val_accuracy: 0.2000\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5050 - accuracy: 0.2000 - val_loss: 0.5049 - val_accuracy: 0.2000\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5050 - accuracy: 0.2000 - val_loss: 0.5049 - val_accuracy: 0.2000\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5050 - accuracy: 0.2000 - val_loss: 0.5049 - val_accuracy: 0.2000\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 0.5050 - accuracy: 0.2000 - val_loss: 0.5049 - val_accuracy: 0.2000\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5049 - accuracy: 0.2000 - val_loss: 0.5049 - val_accuracy: 0.2000\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5049 - accuracy: 0.2000 - val_loss: 0.5048 - val_accuracy: 0.2000\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.5049 - accuracy: 0.2000 - val_loss: 0.5048 - val_accuracy: 0.2000\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5049 - accuracy: 0.2000 - val_loss: 0.5048 - val_accuracy: 0.2000\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5049 - accuracy: 0.2000 - val_loss: 0.5048 - val_accuracy: 0.2000\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5049 - accuracy: 0.2000 - val_loss: 0.5048 - val_accuracy: 0.2000\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5049 - accuracy: 0.2000 - val_loss: 0.5048 - val_accuracy: 0.2000\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5048 - accuracy: 0.2000 - val_loss: 0.5047 - val_accuracy: 0.2000\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5048 - accuracy: 0.2000 - val_loss: 0.5047 - val_accuracy: 0.2000\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5048 - accuracy: 0.2000 - val_loss: 0.5047 - val_accuracy: 0.2000\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5048 - accuracy: 0.2000 - val_loss: 0.5047 - val_accuracy: 0.2000\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5048 - accuracy: 0.2000 - val_loss: 0.5047 - val_accuracy: 0.2000\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5048 - accuracy: 0.2000 - val_loss: 0.5047 - val_accuracy: 0.2000\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5048 - accuracy: 0.2000 - val_loss: 0.5047 - val_accuracy: 0.2000\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5047 - accuracy: 0.2000 - val_loss: 0.5047 - val_accuracy: 0.2000\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 418ms/step - loss: 0.5047 - accuracy: 0.2000 - val_loss: 0.5046 - val_accuracy: 0.2000\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5047 - accuracy: 0.2000 - val_loss: 0.5046 - val_accuracy: 0.2000\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5047 - accuracy: 0.2000 - val_loss: 0.5046 - val_accuracy: 0.2000\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5047 - accuracy: 0.2000 - val_loss: 0.5046 - val_accuracy: 0.2000\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5047 - accuracy: 0.2000 - val_loss: 0.5046 - val_accuracy: 0.2000\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5047 - accuracy: 0.2000 - val_loss: 0.5046 - val_accuracy: 0.2000\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 0.5046 - accuracy: 0.2000 - val_loss: 0.5046 - val_accuracy: 0.2000\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5046 - accuracy: 0.2000 - val_loss: 0.5045 - val_accuracy: 0.2000\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5046 - accuracy: 0.2000 - val_loss: 0.5045 - val_accuracy: 0.2000\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5046 - accuracy: 0.2000 - val_loss: 0.5045 - val_accuracy: 0.2000\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5046 - accuracy: 0.2000 - val_loss: 0.5045 - val_accuracy: 0.2000\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5046 - accuracy: 0.2000 - val_loss: 0.5045 - val_accuracy: 0.2000\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5046 - accuracy: 0.2000 - val_loss: 0.5045 - val_accuracy: 0.2000\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.5046 - accuracy: 0.2000 - val_loss: 0.5045 - val_accuracy: 0.2000\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 0.5045 - accuracy: 0.2000 - val_loss: 0.5044 - val_accuracy: 0.2000\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.5045 - accuracy: 0.2000 - val_loss: 0.5044 - val_accuracy: 0.2000\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5045 - accuracy: 0.2000 - val_loss: 0.5044 - val_accuracy: 0.2000\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5045 - accuracy: 0.2000 - val_loss: 0.5044 - val_accuracy: 0.2000\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.5045 - accuracy: 0.2000 - val_loss: 0.5044 - val_accuracy: 0.2000\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5045 - accuracy: 0.2000 - val_loss: 0.5044 - val_accuracy: 0.2000\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5045 - accuracy: 0.2000 - val_loss: 0.5044 - val_accuracy: 0.2000\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5044 - accuracy: 0.2000 - val_loss: 0.5044 - val_accuracy: 0.2000\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.5044 - accuracy: 0.2000 - val_loss: 0.5043 - val_accuracy: 0.2000\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.5044 - accuracy: 0.2000 - val_loss: 0.5043 - val_accuracy: 0.2000\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 0.5044 - accuracy: 0.2000 - val_loss: 0.5043 - val_accuracy: 0.2000\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 0.5044 - accuracy: 0.2000 - val_loss: 0.5043 - val_accuracy: 0.2000\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.5044 - accuracy: 0.2000 - val_loss: 0.5043 - val_accuracy: 0.2000\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.5044 - accuracy: 0.2000 - val_loss: 0.5043 - val_accuracy: 0.2000\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.5044 - accuracy: 0.2000 - val_loss: 0.5043 - val_accuracy: 0.2000\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5043 - accuracy: 0.2000 - val_loss: 0.5043 - val_accuracy: 0.2000\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.5043 - accuracy: 0.2000 - val_loss: 0.5042 - val_accuracy: 0.2000\n"
     ]
    }
   ],
   "source": [
    "# Vanilla Optimizer\n",
    "model.set_weights(initial_weights)\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd_optimizer)\n",
    "model_fit = model.fit(x=X_train, y=y_train, batch_size=len(y_train), epochs=1000, verbose=\"auto\", callbacks=None,\n",
    "    validation_split=0.0, validation_data=(X_val, y_val), shuffle=True, validation_batch_size=None)\n",
    "\n",
    "train_loss_list = model_fit.history['loss']\n",
    "\n",
    "num_epochs = len(model_fit.epoch)\n",
    "num_epochs_dict['VGD'] = num_epochs\n",
    "loss_dict['VGD'] = train_loss_list\n",
    "\n",
    "train_accuracy, val_accuracy = model_fit.history['accuracy'][-1], model_fit.history['val_accuracy'][-1]\n",
    "\n",
    "eval_dict['VGD'] = (train_accuracy, val_accuracy) \n",
    "\n",
    "with open('model_history_vgd.pkl', 'wb') as f:\n",
    "    pickle.dump(model_fit.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "11385/11385 [==============================] - 56s 5ms/step - loss: 0.4966 - accuracy: 0.2522 - val_loss: 0.4881 - val_accuracy: 0.3281\n",
      "Epoch 2/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.4325 - accuracy: 0.5110 - val_loss: 0.3638 - val_accuracy: 0.6756\n",
      "Epoch 3/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.2861 - accuracy: 0.7331 - val_loss: 0.2227 - val_accuracy: 0.8182\n",
      "Epoch 4/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.1835 - accuracy: 0.8458 - val_loss: 0.1563 - val_accuracy: 0.8669\n",
      "Epoch 5/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.1317 - accuracy: 0.8986 - val_loss: 0.1170 - val_accuracy: 0.9020\n",
      "Epoch 6/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.1016 - accuracy: 0.9224 - val_loss: 0.0966 - val_accuracy: 0.9231\n",
      "Epoch 7/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0854 - accuracy: 0.9330 - val_loss: 0.0861 - val_accuracy: 0.9265\n",
      "Epoch 8/1000\n",
      "11385/11385 [==============================] - 54s 5ms/step - loss: 0.0758 - accuracy: 0.9423 - val_loss: 0.0821 - val_accuracy: 0.9328\n",
      "Epoch 9/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0693 - accuracy: 0.9448 - val_loss: 0.0761 - val_accuracy: 0.9339\n",
      "Epoch 10/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0643 - accuracy: 0.9494 - val_loss: 0.0747 - val_accuracy: 0.9352\n",
      "Epoch 11/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0594 - accuracy: 0.9536 - val_loss: 0.0789 - val_accuracy: 0.9291\n",
      "Epoch 12/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0564 - accuracy: 0.9548 - val_loss: 0.0754 - val_accuracy: 0.9291\n",
      "Epoch 13/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0530 - accuracy: 0.9592 - val_loss: 0.0722 - val_accuracy: 0.9352\n",
      "Epoch 14/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0506 - accuracy: 0.9611 - val_loss: 0.0745 - val_accuracy: 0.9357\n",
      "Epoch 15/1000\n",
      "11385/11385 [==============================] - 54s 5ms/step - loss: 0.0481 - accuracy: 0.9625 - val_loss: 0.0748 - val_accuracy: 0.9349\n",
      "Epoch 16/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0459 - accuracy: 0.9622 - val_loss: 0.0777 - val_accuracy: 0.9349\n",
      "Epoch 17/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0435 - accuracy: 0.9665 - val_loss: 0.0723 - val_accuracy: 0.9349\n",
      "Epoch 18/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0426 - accuracy: 0.9662 - val_loss: 0.0765 - val_accuracy: 0.9315\n",
      "Epoch 19/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0406 - accuracy: 0.9674 - val_loss: 0.0741 - val_accuracy: 0.9328\n",
      "Epoch 20/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0389 - accuracy: 0.9697 - val_loss: 0.0770 - val_accuracy: 0.9312\n",
      "Epoch 21/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0371 - accuracy: 0.9722 - val_loss: 0.0735 - val_accuracy: 0.9360\n",
      "Epoch 22/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0371 - accuracy: 0.9701 - val_loss: 0.0758 - val_accuracy: 0.9362\n",
      "Epoch 23/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0347 - accuracy: 0.9745 - val_loss: 0.0807 - val_accuracy: 0.9260\n",
      "Epoch 24/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0338 - accuracy: 0.9728 - val_loss: 0.0778 - val_accuracy: 0.9325\n",
      "Epoch 25/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0327 - accuracy: 0.9737 - val_loss: 0.0792 - val_accuracy: 0.9310\n",
      "Epoch 26/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0318 - accuracy: 0.9746 - val_loss: 0.0829 - val_accuracy: 0.9281\n",
      "Epoch 27/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0300 - accuracy: 0.9765 - val_loss: 0.0827 - val_accuracy: 0.9289\n",
      "Epoch 28/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0292 - accuracy: 0.9797 - val_loss: 0.0811 - val_accuracy: 0.9312\n",
      "Epoch 29/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0284 - accuracy: 0.9790 - val_loss: 0.0808 - val_accuracy: 0.9307\n",
      "Epoch 30/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0269 - accuracy: 0.9808 - val_loss: 0.0882 - val_accuracy: 0.9262\n",
      "Epoch 31/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0262 - accuracy: 0.9807 - val_loss: 0.0839 - val_accuracy: 0.9315\n",
      "Epoch 32/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0253 - accuracy: 0.9814 - val_loss: 0.0871 - val_accuracy: 0.9318\n",
      "Epoch 33/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0241 - accuracy: 0.9820 - val_loss: 0.0848 - val_accuracy: 0.9312\n",
      "Epoch 34/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0238 - accuracy: 0.9829 - val_loss: 0.0887 - val_accuracy: 0.9315\n",
      "Epoch 35/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0233 - accuracy: 0.9823 - val_loss: 0.0928 - val_accuracy: 0.9257\n",
      "Epoch 36/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0220 - accuracy: 0.9845 - val_loss: 0.0884 - val_accuracy: 0.9318\n",
      "Epoch 37/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0213 - accuracy: 0.9852 - val_loss: 0.0932 - val_accuracy: 0.9275\n",
      "Epoch 38/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0206 - accuracy: 0.9845 - val_loss: 0.0941 - val_accuracy: 0.9310\n",
      "Epoch 39/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0202 - accuracy: 0.9859 - val_loss: 0.0927 - val_accuracy: 0.9291\n",
      "Epoch 40/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0188 - accuracy: 0.9870 - val_loss: 0.0928 - val_accuracy: 0.9302\n",
      "Epoch 41/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0187 - accuracy: 0.9870 - val_loss: 0.0926 - val_accuracy: 0.9302\n",
      "Epoch 42/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0179 - accuracy: 0.9872 - val_loss: 0.0963 - val_accuracy: 0.9312\n",
      "Epoch 43/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0173 - accuracy: 0.9881 - val_loss: 0.0966 - val_accuracy: 0.9270\n",
      "Epoch 44/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0165 - accuracy: 0.9899 - val_loss: 0.0957 - val_accuracy: 0.9296\n",
      "Epoch 45/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0157 - accuracy: 0.9899 - val_loss: 0.0992 - val_accuracy: 0.9294\n",
      "Epoch 46/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0151 - accuracy: 0.9912 - val_loss: 0.1006 - val_accuracy: 0.9286\n",
      "Epoch 47/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0140 - accuracy: 0.9923 - val_loss: 0.1002 - val_accuracy: 0.9302\n",
      "Epoch 48/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0141 - accuracy: 0.9920 - val_loss: 0.1034 - val_accuracy: 0.9283\n",
      "Epoch 49/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0132 - accuracy: 0.9921 - val_loss: 0.1012 - val_accuracy: 0.9299\n"
     ]
    }
   ],
   "source": [
    "# SGD with momentum (generalized delta rule)\n",
    "model.set_weights(initial_weights)\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=momentum_optimizer)\n",
    "model_fit = model.fit(x=X_train, y=y_train, batch_size=1, epochs=1000, verbose=\"auto\", callbacks=[\n",
    "   average_loss_callback,\n",
    "   ModelCheckpoint(filepath=f\"model_checkpoint_{model.optimizer.get_config()['name']}.h5\",\n",
    "                   save_best_only=True,  # Only save the best performing model\n",
    "                    monitor='loss',  # Monitor the validation loss\n",
    "                    mode='min',          # Minimize the validation loss\n",
    "                    save_weights_only=False, # Save the entire model (including optimizer state)\n",
    "                    append_history=True,),\n",
    "   TensorBoard(log_dir='./logs')],\n",
    "    validation_split=0.0, validation_data=(X_val, y_val), shuffle=True, validation_batch_size=None)\n",
    "\n",
    "train_loss_list = model_fit.history['loss']\n",
    "\n",
    "num_epochs = len(model_fit.epoch)\n",
    "num_epochs_dict['momentum'] = num_epochs\n",
    "loss_dict['momentum'] = train_loss_list\n",
    "\n",
    "train_accuracy, val_accuracy = model_fit.history['accuracy'][-1], model_fit.history['val_accuracy'][-1]\n",
    "\n",
    "eval_dict['momentum'] = (train_accuracy, val_accuracy) \n",
    "\n",
    "with open('model_history_momentum.pkl', 'wb') as f:\n",
    "    pickle.dump(model_fit.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "11385/11385 [==============================] - 54s 5ms/step - loss: 0.4966 - accuracy: 0.2473 - val_loss: 0.4821 - val_accuracy: 0.2448\n",
      "Epoch 2/1000\n",
      "11385/11385 [==============================] - 50s 4ms/step - loss: 0.4323 - accuracy: 0.5047 - val_loss: 0.3594 - val_accuracy: 0.6838\n",
      "Epoch 3/1000\n",
      "11385/11385 [==============================] - 53s 5ms/step - loss: 0.2843 - accuracy: 0.7369 - val_loss: 0.2231 - val_accuracy: 0.7942\n",
      "Epoch 4/1000\n",
      "11385/11385 [==============================] - 52s 5ms/step - loss: 0.1819 - accuracy: 0.8518 - val_loss: 0.1540 - val_accuracy: 0.8709\n",
      "Epoch 5/1000\n",
      "11385/11385 [==============================] - 54s 5ms/step - loss: 0.1305 - accuracy: 0.8978 - val_loss: 0.1150 - val_accuracy: 0.9078\n",
      "Epoch 6/1000\n",
      "11385/11385 [==============================] - 65s 6ms/step - loss: 0.1012 - accuracy: 0.9231 - val_loss: 0.1096 - val_accuracy: 0.8996\n",
      "Epoch 7/1000\n",
      "11385/11385 [==============================] - 61s 5ms/step - loss: 0.0852 - accuracy: 0.9346 - val_loss: 0.0911 - val_accuracy: 0.9202\n",
      "Epoch 8/1000\n",
      "11385/11385 [==============================] - 62s 5ms/step - loss: 0.0754 - accuracy: 0.9410 - val_loss: 0.0846 - val_accuracy: 0.9267\n",
      "Epoch 9/1000\n",
      "11385/11385 [==============================] - 61s 5ms/step - loss: 0.0689 - accuracy: 0.9464 - val_loss: 0.0812 - val_accuracy: 0.9278\n",
      "Epoch 10/1000\n",
      "11385/11385 [==============================] - 64s 6ms/step - loss: 0.0643 - accuracy: 0.9491 - val_loss: 0.0782 - val_accuracy: 0.9302\n",
      "Epoch 11/1000\n",
      "11385/11385 [==============================] - 62s 5ms/step - loss: 0.0599 - accuracy: 0.9527 - val_loss: 0.0749 - val_accuracy: 0.9336\n",
      "Epoch 12/1000\n",
      "11385/11385 [==============================] - 66s 6ms/step - loss: 0.0559 - accuracy: 0.9558 - val_loss: 0.0820 - val_accuracy: 0.9331\n",
      "Epoch 13/1000\n",
      "11385/11385 [==============================] - 65s 6ms/step - loss: 0.0534 - accuracy: 0.9576 - val_loss: 0.0744 - val_accuracy: 0.9339\n",
      "Epoch 14/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.0502 - accuracy: 0.9605 - val_loss: 0.0781 - val_accuracy: 0.9323\n",
      "Epoch 15/1000\n",
      "11385/11385 [==============================] - 58s 5ms/step - loss: 0.0481 - accuracy: 0.9612 - val_loss: 0.0742 - val_accuracy: 0.9323\n",
      "Epoch 16/1000\n",
      "11385/11385 [==============================] - 61s 5ms/step - loss: 0.0461 - accuracy: 0.9638 - val_loss: 0.0747 - val_accuracy: 0.9318\n",
      "Epoch 17/1000\n",
      "11385/11385 [==============================] - 70s 6ms/step - loss: 0.0440 - accuracy: 0.9647 - val_loss: 0.0782 - val_accuracy: 0.9291\n",
      "Epoch 18/1000\n",
      "11385/11385 [==============================] - 66s 6ms/step - loss: 0.0421 - accuracy: 0.9689 - val_loss: 0.0768 - val_accuracy: 0.9344\n",
      "Epoch 19/1000\n",
      "11385/11385 [==============================] - 57s 5ms/step - loss: 0.0409 - accuracy: 0.9674 - val_loss: 0.0746 - val_accuracy: 0.9383\n",
      "Epoch 20/1000\n",
      "11385/11385 [==============================] - 61s 5ms/step - loss: 0.0394 - accuracy: 0.9681 - val_loss: 0.0756 - val_accuracy: 0.9291\n",
      "Epoch 21/1000\n",
      "11385/11385 [==============================] - 63s 6ms/step - loss: 0.0375 - accuracy: 0.9715 - val_loss: 0.0884 - val_accuracy: 0.9238\n",
      "Epoch 22/1000\n",
      "11385/11385 [==============================] - 58s 5ms/step - loss: 0.0362 - accuracy: 0.9727 - val_loss: 0.0796 - val_accuracy: 0.9310\n",
      "Epoch 23/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.0350 - accuracy: 0.9734 - val_loss: 0.0834 - val_accuracy: 0.9281\n",
      "Epoch 24/1000\n",
      "11385/11385 [==============================] - 58s 5ms/step - loss: 0.0334 - accuracy: 0.9741 - val_loss: 0.0791 - val_accuracy: 0.9310\n",
      "Epoch 25/1000\n",
      "11385/11385 [==============================] - 62s 5ms/step - loss: 0.0322 - accuracy: 0.9750 - val_loss: 0.0785 - val_accuracy: 0.9365\n",
      "Epoch 26/1000\n",
      "11385/11385 [==============================] - 69s 6ms/step - loss: 0.0318 - accuracy: 0.9741 - val_loss: 0.0836 - val_accuracy: 0.9265\n",
      "Epoch 27/1000\n",
      "11385/11385 [==============================] - 69s 6ms/step - loss: 0.0299 - accuracy: 0.9774 - val_loss: 0.0833 - val_accuracy: 0.9336\n",
      "Epoch 28/1000\n",
      "11385/11385 [==============================] - 56s 5ms/step - loss: 0.0291 - accuracy: 0.9789 - val_loss: 0.0804 - val_accuracy: 0.9365\n",
      "Epoch 29/1000\n",
      "11385/11385 [==============================] - 56s 5ms/step - loss: 0.0284 - accuracy: 0.9794 - val_loss: 0.0839 - val_accuracy: 0.9315\n",
      "Epoch 30/1000\n",
      "11385/11385 [==============================] - 56s 5ms/step - loss: 0.0270 - accuracy: 0.9804 - val_loss: 0.0816 - val_accuracy: 0.9312\n",
      "Epoch 31/1000\n",
      "11385/11385 [==============================] - 56s 5ms/step - loss: 0.0263 - accuracy: 0.9820 - val_loss: 0.0862 - val_accuracy: 0.9299\n",
      "Epoch 32/1000\n",
      "11385/11385 [==============================] - 110s 10ms/step - loss: 0.0253 - accuracy: 0.9815 - val_loss: 0.0855 - val_accuracy: 0.9307\n",
      "Epoch 33/1000\n",
      "11385/11385 [==============================] - 82s 7ms/step - loss: 0.0244 - accuracy: 0.9818 - val_loss: 0.1016 - val_accuracy: 0.9199\n",
      "Epoch 34/1000\n",
      "11385/11385 [==============================] - 81s 7ms/step - loss: 0.0236 - accuracy: 0.9826 - val_loss: 0.0911 - val_accuracy: 0.9254\n",
      "Epoch 35/1000\n",
      "11385/11385 [==============================] - 84s 7ms/step - loss: 0.0229 - accuracy: 0.9838 - val_loss: 0.0872 - val_accuracy: 0.9310\n",
      "Epoch 36/1000\n",
      "11385/11385 [==============================] - 105s 9ms/step - loss: 0.0223 - accuracy: 0.9845 - val_loss: 0.0898 - val_accuracy: 0.9307\n",
      "Epoch 37/1000\n",
      "11385/11385 [==============================] - 82s 7ms/step - loss: 0.0210 - accuracy: 0.9856 - val_loss: 0.0887 - val_accuracy: 0.9299\n",
      "Epoch 38/1000\n",
      "11385/11385 [==============================] - 81s 7ms/step - loss: 0.0207 - accuracy: 0.9855 - val_loss: 0.0919 - val_accuracy: 0.9315\n",
      "Epoch 39/1000\n",
      "11385/11385 [==============================] - 83s 7ms/step - loss: 0.0193 - accuracy: 0.9875 - val_loss: 0.0908 - val_accuracy: 0.9289\n",
      "Epoch 40/1000\n",
      "11385/11385 [==============================] - 84s 7ms/step - loss: 0.0196 - accuracy: 0.9857 - val_loss: 0.0925 - val_accuracy: 0.9325\n",
      "Epoch 41/1000\n",
      "11385/11385 [==============================] - 79s 7ms/step - loss: 0.0184 - accuracy: 0.9882 - val_loss: 0.0926 - val_accuracy: 0.9291\n",
      "Epoch 42/1000\n",
      "11385/11385 [==============================] - 82s 7ms/step - loss: 0.0176 - accuracy: 0.9890 - val_loss: 0.0988 - val_accuracy: 0.9252\n",
      "Epoch 43/1000\n",
      "11385/11385 [==============================] - 109s 10ms/step - loss: 0.0174 - accuracy: 0.9886 - val_loss: 0.0937 - val_accuracy: 0.9312\n",
      "Epoch 44/1000\n",
      "11385/11385 [==============================] - 61s 5ms/step - loss: 0.0163 - accuracy: 0.9891 - val_loss: 0.0993 - val_accuracy: 0.9291\n",
      "Epoch 45/1000\n",
      "11385/11385 [==============================] - 61s 5ms/step - loss: 0.0154 - accuracy: 0.9903 - val_loss: 0.0975 - val_accuracy: 0.9286\n",
      "Epoch 46/1000\n",
      "11385/11385 [==============================] - 61s 5ms/step - loss: 0.0150 - accuracy: 0.9905 - val_loss: 0.1024 - val_accuracy: 0.9291\n",
      "Epoch 47/1000\n",
      "11385/11385 [==============================] - 61s 5ms/step - loss: 0.0145 - accuracy: 0.9920 - val_loss: 0.0985 - val_accuracy: 0.9315\n",
      "Epoch 48/1000\n",
      "11385/11385 [==============================] - 61s 5ms/step - loss: 0.0134 - accuracy: 0.9925 - val_loss: 0.1007 - val_accuracy: 0.9299\n",
      "Epoch 49/1000\n",
      "11385/11385 [==============================] - 61s 5ms/step - loss: 0.0132 - accuracy: 0.9928 - val_loss: 0.1015 - val_accuracy: 0.9283\n",
      "Epoch 50/1000\n",
      "11385/11385 [==============================] - 61s 5ms/step - loss: 0.0127 - accuracy: 0.9938 - val_loss: 0.1030 - val_accuracy: 0.9323\n",
      "Epoch 51/1000\n",
      "11385/11385 [==============================] - 61s 5ms/step - loss: 0.0123 - accuracy: 0.9931 - val_loss: 0.1029 - val_accuracy: 0.9294\n"
     ]
    }
   ],
   "source": [
    "# SGD with momentum (NAG)\n",
    "model.set_weights(initial_weights)\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=nag_optimizer)\n",
    "model_fit = model.fit(x=X_train, y=y_train, batch_size=1, epochs=1000, verbose=\"auto\", callbacks=[\n",
    "   average_loss_callback,\n",
    "   ModelCheckpoint(filepath=f\"model_checkpoint_{model.optimizer.get_config()['name']}.h5\",\n",
    "                   save_best_only=True,  # Only save the best performing model\n",
    "                    monitor='loss',  # Monitor the validation loss\n",
    "                    mode='min',          # Minimize the validation loss\n",
    "                    save_weights_only=False, # Save the entire model (including optimizer state)\n",
    "                    append_history=True,),\n",
    "   TensorBoard(log_dir='./logs')],\n",
    "    validation_split=0.0, validation_data=(X_val, y_val), shuffle=True, validation_batch_size=None)\n",
    "\n",
    "train_loss_list = model_fit.history['loss']\n",
    "\n",
    "num_epochs = len(model_fit.epoch)\n",
    "num_epochs_dict['NAG'] = num_epochs\n",
    "loss_dict['NAG'] = train_loss_list\n",
    "\n",
    "train_accuracy, val_accuracy = model_fit.history['accuracy'][-1], model_fit.history['val_accuracy'][-1]\n",
    "\n",
    "eval_dict['NAG'] = (train_accuracy, val_accuracy) \n",
    "\n",
    "with open('model_history_nag.pkl', 'wb') as f:\n",
    "    pickle.dump(model_fit.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.5005 - accuracy: 0.2462 - val_loss: 0.4969 - val_accuracy: 0.2846\n",
      "Epoch 2/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.4953 - accuracy: 0.3722 - val_loss: 0.4930 - val_accuracy: 0.4105\n",
      "Epoch 3/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.4907 - accuracy: 0.4094 - val_loss: 0.4880 - val_accuracy: 0.6427\n",
      "Epoch 4/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.4849 - accuracy: 0.6039 - val_loss: 0.4811 - val_accuracy: 0.5686\n",
      "Epoch 5/1000\n",
      "11385/11385 [==============================] - 66s 6ms/step - loss: 0.4766 - accuracy: 0.6082 - val_loss: 0.4715 - val_accuracy: 0.6735\n",
      "Epoch 6/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.4650 - accuracy: 0.6376 - val_loss: 0.4582 - val_accuracy: 0.6904\n",
      "Epoch 7/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.4496 - accuracy: 0.6814 - val_loss: 0.4408 - val_accuracy: 0.6825\n",
      "Epoch 8/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.4307 - accuracy: 0.6829 - val_loss: 0.4212 - val_accuracy: 0.6585\n",
      "Epoch 9/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.4104 - accuracy: 0.6848 - val_loss: 0.4009 - val_accuracy: 0.6379\n",
      "Epoch 10/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.3907 - accuracy: 0.6983 - val_loss: 0.3817 - val_accuracy: 0.7080\n",
      "Epoch 11/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.3716 - accuracy: 0.7246 - val_loss: 0.3633 - val_accuracy: 0.7296\n",
      "Epoch 12/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.3530 - accuracy: 0.7480 - val_loss: 0.3448 - val_accuracy: 0.7449\n",
      "Epoch 13/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.3346 - accuracy: 0.7643 - val_loss: 0.3272 - val_accuracy: 0.7639\n",
      "Epoch 14/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.3170 - accuracy: 0.7788 - val_loss: 0.3103 - val_accuracy: 0.7631\n",
      "Epoch 15/1000\n",
      "11385/11385 [==============================] - 61s 5ms/step - loss: 0.3004 - accuracy: 0.7911 - val_loss: 0.2950 - val_accuracy: 0.7842\n",
      "Epoch 16/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.2853 - accuracy: 0.8000 - val_loss: 0.2806 - val_accuracy: 0.7810\n",
      "Epoch 17/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.2715 - accuracy: 0.8061 - val_loss: 0.2675 - val_accuracy: 0.8032\n",
      "Epoch 18/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.2589 - accuracy: 0.8187 - val_loss: 0.2559 - val_accuracy: 0.8058\n",
      "Epoch 19/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.2476 - accuracy: 0.8245 - val_loss: 0.2450 - val_accuracy: 0.8179\n",
      "Epoch 20/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.2372 - accuracy: 0.8336 - val_loss: 0.2353 - val_accuracy: 0.8224\n",
      "Epoch 21/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.2277 - accuracy: 0.8390 - val_loss: 0.2261 - val_accuracy: 0.8327\n",
      "Epoch 22/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.2189 - accuracy: 0.8489 - val_loss: 0.2178 - val_accuracy: 0.8393\n",
      "Epoch 23/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.2107 - accuracy: 0.8547 - val_loss: 0.2098 - val_accuracy: 0.8490\n",
      "Epoch 24/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.2030 - accuracy: 0.8605 - val_loss: 0.2023 - val_accuracy: 0.8540\n",
      "Epoch 25/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.1958 - accuracy: 0.8679 - val_loss: 0.1956 - val_accuracy: 0.8596\n",
      "Epoch 26/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.1891 - accuracy: 0.8732 - val_loss: 0.1893 - val_accuracy: 0.8675\n",
      "Epoch 27/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.1827 - accuracy: 0.8798 - val_loss: 0.1832 - val_accuracy: 0.8677\n",
      "Epoch 28/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.1769 - accuracy: 0.8844 - val_loss: 0.1774 - val_accuracy: 0.8777\n",
      "Epoch 29/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.1713 - accuracy: 0.8889 - val_loss: 0.1720 - val_accuracy: 0.8835\n",
      "Epoch 30/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.1661 - accuracy: 0.8935 - val_loss: 0.1671 - val_accuracy: 0.8862\n",
      "Epoch 31/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.1612 - accuracy: 0.8972 - val_loss: 0.1625 - val_accuracy: 0.8917\n",
      "Epoch 32/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.1565 - accuracy: 0.9000 - val_loss: 0.1581 - val_accuracy: 0.8928\n",
      "Epoch 33/1000\n",
      "11385/11385 [==============================] - 61s 5ms/step - loss: 0.1522 - accuracy: 0.9051 - val_loss: 0.1542 - val_accuracy: 0.8938\n",
      "Epoch 34/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.1481 - accuracy: 0.9061 - val_loss: 0.1501 - val_accuracy: 0.8983\n",
      "Epoch 35/1000\n",
      "11385/11385 [==============================] - 62s 5ms/step - loss: 0.1443 - accuracy: 0.9099 - val_loss: 0.1466 - val_accuracy: 0.8993\n",
      "Epoch 36/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.1406 - accuracy: 0.9122 - val_loss: 0.1434 - val_accuracy: 0.8988\n",
      "Epoch 37/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.1372 - accuracy: 0.9137 - val_loss: 0.1401 - val_accuracy: 0.9020\n",
      "Epoch 38/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.1340 - accuracy: 0.9166 - val_loss: 0.1372 - val_accuracy: 0.9033\n",
      "Epoch 39/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.1310 - accuracy: 0.9194 - val_loss: 0.1345 - val_accuracy: 0.9049\n",
      "Epoch 40/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.1282 - accuracy: 0.9208 - val_loss: 0.1317 - val_accuracy: 0.9078\n",
      "Epoch 41/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.1255 - accuracy: 0.9220 - val_loss: 0.1294 - val_accuracy: 0.9101\n",
      "Epoch 42/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.1229 - accuracy: 0.9248 - val_loss: 0.1271 - val_accuracy: 0.9096\n",
      "Epoch 43/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.1205 - accuracy: 0.9256 - val_loss: 0.1249 - val_accuracy: 0.9123\n",
      "Epoch 44/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.1181 - accuracy: 0.9275 - val_loss: 0.1231 - val_accuracy: 0.9123\n",
      "Epoch 45/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.1161 - accuracy: 0.9286 - val_loss: 0.1211 - val_accuracy: 0.9125\n",
      "Epoch 46/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.1140 - accuracy: 0.9291 - val_loss: 0.1193 - val_accuracy: 0.9133\n",
      "Epoch 47/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.1121 - accuracy: 0.9303 - val_loss: 0.1176 - val_accuracy: 0.9133\n",
      "Epoch 48/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.1103 - accuracy: 0.9316 - val_loss: 0.1159 - val_accuracy: 0.9162\n",
      "Epoch 49/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.1084 - accuracy: 0.9332 - val_loss: 0.1143 - val_accuracy: 0.9186\n",
      "Epoch 50/1000\n",
      "11385/11385 [==============================] - 60s 5ms/step - loss: 0.1068 - accuracy: 0.9344 - val_loss: 0.1127 - val_accuracy: 0.9183\n",
      "Epoch 51/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.1051 - accuracy: 0.9341 - val_loss: 0.1114 - val_accuracy: 0.9207\n",
      "Epoch 52/1000\n",
      "11385/11385 [==============================] - 58s 5ms/step - loss: 0.1037 - accuracy: 0.9348 - val_loss: 0.1100 - val_accuracy: 0.9220\n",
      "Epoch 53/1000\n",
      "11385/11385 [==============================] - 58s 5ms/step - loss: 0.1022 - accuracy: 0.9348 - val_loss: 0.1086 - val_accuracy: 0.9207\n",
      "Epoch 54/1000\n",
      "11385/11385 [==============================] - 58s 5ms/step - loss: 0.1007 - accuracy: 0.9359 - val_loss: 0.1074 - val_accuracy: 0.9207\n",
      "Epoch 55/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.0994 - accuracy: 0.9373 - val_loss: 0.1063 - val_accuracy: 0.9225\n",
      "Epoch 56/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.0981 - accuracy: 0.9368 - val_loss: 0.1052 - val_accuracy: 0.9231\n",
      "Epoch 57/1000\n",
      "11385/11385 [==============================] - 56s 5ms/step - loss: 0.0969 - accuracy: 0.9390 - val_loss: 0.1041 - val_accuracy: 0.9220\n",
      "Epoch 58/1000\n",
      "11385/11385 [==============================] - 57s 5ms/step - loss: 0.0957 - accuracy: 0.9389 - val_loss: 0.1030 - val_accuracy: 0.9238\n",
      "Epoch 59/1000\n",
      "11385/11385 [==============================] - 63s 6ms/step - loss: 0.0945 - accuracy: 0.9392 - val_loss: 0.1021 - val_accuracy: 0.9233\n",
      "Epoch 60/1000\n",
      "11385/11385 [==============================] - 58s 5ms/step - loss: 0.0933 - accuracy: 0.9396 - val_loss: 0.1011 - val_accuracy: 0.9254\n",
      "Epoch 61/1000\n",
      "11385/11385 [==============================] - 58s 5ms/step - loss: 0.0923 - accuracy: 0.9398 - val_loss: 0.1006 - val_accuracy: 0.9249\n",
      "Epoch 62/1000\n",
      "11385/11385 [==============================] - 58s 5ms/step - loss: 0.0913 - accuracy: 0.9416 - val_loss: 0.0996 - val_accuracy: 0.9238\n",
      "Epoch 63/1000\n",
      "11385/11385 [==============================] - 58s 5ms/step - loss: 0.0903 - accuracy: 0.9417 - val_loss: 0.0986 - val_accuracy: 0.9244\n",
      "Epoch 64/1000\n",
      "11385/11385 [==============================] - 58s 5ms/step - loss: 0.0893 - accuracy: 0.9416 - val_loss: 0.0979 - val_accuracy: 0.9281\n",
      "Epoch 65/1000\n",
      "11385/11385 [==============================] - 58s 5ms/step - loss: 0.0884 - accuracy: 0.9427 - val_loss: 0.0970 - val_accuracy: 0.9260\n",
      "Epoch 66/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.0874 - accuracy: 0.9436 - val_loss: 0.0965 - val_accuracy: 0.9252\n",
      "Epoch 67/1000\n",
      "11385/11385 [==============================] - 58s 5ms/step - loss: 0.0866 - accuracy: 0.9446 - val_loss: 0.0958 - val_accuracy: 0.9249\n",
      "Epoch 68/1000\n",
      "11385/11385 [==============================] - 58s 5ms/step - loss: 0.0858 - accuracy: 0.9442 - val_loss: 0.0947 - val_accuracy: 0.9281\n",
      "Epoch 69/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.0849 - accuracy: 0.9444 - val_loss: 0.0942 - val_accuracy: 0.9283\n",
      "Epoch 70/1000\n",
      "11385/11385 [==============================] - 58s 5ms/step - loss: 0.0841 - accuracy: 0.9458 - val_loss: 0.0936 - val_accuracy: 0.9283\n",
      "Epoch 71/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.0834 - accuracy: 0.9450 - val_loss: 0.0930 - val_accuracy: 0.9275\n",
      "Epoch 72/1000\n",
      "11385/11385 [==============================] - 58s 5ms/step - loss: 0.0826 - accuracy: 0.9461 - val_loss: 0.0925 - val_accuracy: 0.9273\n",
      "Epoch 73/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.0820 - accuracy: 0.9468 - val_loss: 0.0917 - val_accuracy: 0.9283\n",
      "Epoch 74/1000\n",
      "11385/11385 [==============================] - 66s 6ms/step - loss: 0.0812 - accuracy: 0.9469 - val_loss: 0.0911 - val_accuracy: 0.9289\n",
      "Epoch 75/1000\n",
      "11385/11385 [==============================] - 62s 5ms/step - loss: 0.0805 - accuracy: 0.9469 - val_loss: 0.0906 - val_accuracy: 0.9289\n",
      "Epoch 76/1000\n",
      "11385/11385 [==============================] - 57s 5ms/step - loss: 0.0798 - accuracy: 0.9474 - val_loss: 0.0903 - val_accuracy: 0.9291\n",
      "Epoch 77/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0792 - accuracy: 0.9479 - val_loss: 0.0896 - val_accuracy: 0.9299\n",
      "Epoch 78/1000\n",
      "11385/11385 [==============================] - 53s 5ms/step - loss: 0.0786 - accuracy: 0.9481 - val_loss: 0.0890 - val_accuracy: 0.9302\n",
      "Epoch 79/1000\n",
      "11385/11385 [==============================] - 53s 5ms/step - loss: 0.0779 - accuracy: 0.9497 - val_loss: 0.0886 - val_accuracy: 0.9294\n",
      "Epoch 80/1000\n",
      "11385/11385 [==============================] - 63s 6ms/step - loss: 0.0773 - accuracy: 0.9491 - val_loss: 0.0884 - val_accuracy: 0.9294\n",
      "Epoch 81/1000\n",
      "11385/11385 [==============================] - 53s 5ms/step - loss: 0.0767 - accuracy: 0.9499 - val_loss: 0.0878 - val_accuracy: 0.9289\n",
      "Epoch 82/1000\n",
      "11385/11385 [==============================] - 54s 5ms/step - loss: 0.0762 - accuracy: 0.9492 - val_loss: 0.0872 - val_accuracy: 0.9299\n",
      "Epoch 83/1000\n",
      "11385/11385 [==============================] - 55s 5ms/step - loss: 0.0756 - accuracy: 0.9497 - val_loss: 0.0868 - val_accuracy: 0.9310\n",
      "Epoch 84/1000\n",
      "11385/11385 [==============================] - 53s 5ms/step - loss: 0.0750 - accuracy: 0.9498 - val_loss: 0.0863 - val_accuracy: 0.9307\n",
      "Epoch 85/1000\n",
      "11385/11385 [==============================] - 52s 5ms/step - loss: 0.0745 - accuracy: 0.9507 - val_loss: 0.0861 - val_accuracy: 0.9310\n",
      "Epoch 86/1000\n",
      "11385/11385 [==============================] - 54s 5ms/step - loss: 0.0740 - accuracy: 0.9503 - val_loss: 0.0858 - val_accuracy: 0.9302\n",
      "Epoch 87/1000\n",
      "11385/11385 [==============================] - 54s 5ms/step - loss: 0.0735 - accuracy: 0.9513 - val_loss: 0.0852 - val_accuracy: 0.9310\n",
      "Epoch 88/1000\n",
      "11385/11385 [==============================] - 53s 5ms/step - loss: 0.0730 - accuracy: 0.9514 - val_loss: 0.0850 - val_accuracy: 0.9323\n",
      "Epoch 89/1000\n",
      "11385/11385 [==============================] - 59s 5ms/step - loss: 0.0725 - accuracy: 0.9514 - val_loss: 0.0846 - val_accuracy: 0.9296\n",
      "Epoch 90/1000\n",
      "11385/11385 [==============================] - 63s 6ms/step - loss: 0.0721 - accuracy: 0.9514 - val_loss: 0.0842 - val_accuracy: 0.9312\n",
      "Epoch 91/1000\n",
      "11385/11385 [==============================] - 54s 5ms/step - loss: 0.0716 - accuracy: 0.9523 - val_loss: 0.0839 - val_accuracy: 0.9307\n"
     ]
    }
   ],
   "source": [
    "# AdaGrad\n",
    "model.set_weights(initial_weights)\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=adagrad_optimizer)\n",
    "model_fit = model.fit(x=X_train, y=y_train, batch_size=1, epochs=1000, verbose=\"auto\", callbacks=[\n",
    "   average_loss_callback,\n",
    "   ModelCheckpoint(filepath=f\"model_checkpoint_{model.optimizer.get_config()['name']}.h5\",\n",
    "                   save_best_only=True,  # Only save the best performing model\n",
    "                    monitor='loss',  # Monitor the validation loss\n",
    "                    mode='min',          # Minimize the validation loss\n",
    "                    save_weights_only=False, # Save the entire model (including optimizer state)\n",
    "                    append_history=True,),\n",
    "   TensorBoard(log_dir='./logs')],\n",
    "    validation_split=0.0, validation_data=(X_val, y_val), shuffle=True, validation_batch_size=None)\n",
    "\n",
    "train_loss_list = model_fit.history['loss']\n",
    "\n",
    "num_epochs = len(model_fit.epoch)\n",
    "num_epochs_dict['adaGrad'] = num_epochs\n",
    "loss_dict['adaGrad'] = train_loss_list\n",
    "\n",
    "train_accuracy, val_accuracy = model_fit.history['accuracy'][-1], model_fit.history['val_accuracy'][-1]\n",
    "\n",
    "eval_dict['adaGrad'] = (train_accuracy, val_accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "11385/11385 [==============================] - 152s 13ms/step - loss: 0.1621 - accuracy: 0.8401 - val_loss: 0.0807 - val_accuracy: 0.9291\n",
      "Epoch 2/1000\n",
      "11385/11385 [==============================] - 159s 14ms/step - loss: 0.0889 - accuracy: 0.9276 - val_loss: 0.0872 - val_accuracy: 0.9273\n",
      "Epoch 3/1000\n",
      "11385/11385 [==============================] - 149s 13ms/step - loss: 0.0719 - accuracy: 0.9463 - val_loss: 0.1798 - val_accuracy: 0.9080\n",
      "Epoch 4/1000\n",
      "11385/11385 [==============================] - 152s 13ms/step - loss: 0.0605 - accuracy: 0.9561 - val_loss: 0.1135 - val_accuracy: 0.9394\n",
      "Epoch 5/1000\n",
      "11385/11385 [==============================] - 135s 12ms/step - loss: 0.0476 - accuracy: 0.9669 - val_loss: 0.1378 - val_accuracy: 0.9004\n",
      "Epoch 6/1000\n",
      "11385/11385 [==============================] - 136s 12ms/step - loss: 0.0455 - accuracy: 0.9701 - val_loss: 0.0907 - val_accuracy: 0.9465\n",
      "Epoch 7/1000\n",
      "11385/11385 [==============================] - 147s 13ms/step - loss: 0.0371 - accuracy: 0.9758 - val_loss: 0.1183 - val_accuracy: 0.9433\n",
      "Epoch 8/1000\n",
      "11385/11385 [==============================] - 139s 12ms/step - loss: 0.0332 - accuracy: 0.9805 - val_loss: 0.1424 - val_accuracy: 0.9478\n",
      "Epoch 9/1000\n",
      "11385/11385 [==============================] - 139s 12ms/step - loss: 0.0281 - accuracy: 0.9845 - val_loss: 0.1453 - val_accuracy: 0.9470\n",
      "Epoch 10/1000\n",
      "11385/11385 [==============================] - 141s 12ms/step - loss: 0.0279 - accuracy: 0.9850 - val_loss: 0.1347 - val_accuracy: 0.9444\n",
      "Epoch 11/1000\n",
      "11385/11385 [==============================] - 145s 13ms/step - loss: 0.0212 - accuracy: 0.9887 - val_loss: 0.1289 - val_accuracy: 0.9447\n",
      "Epoch 12/1000\n",
      "11385/11385 [==============================] - 138s 12ms/step - loss: 0.0221 - accuracy: 0.9888 - val_loss: 0.1850 - val_accuracy: 0.9441\n",
      "Epoch 13/1000\n",
      "11385/11385 [==============================] - 132s 12ms/step - loss: 0.0170 - accuracy: 0.9918 - val_loss: 0.2035 - val_accuracy: 0.9381\n",
      "Epoch 14/1000\n",
      "11385/11385 [==============================] - 128s 11ms/step - loss: 0.0159 - accuracy: 0.9935 - val_loss: 0.1757 - val_accuracy: 0.9494\n",
      "Epoch 15/1000\n",
      "11385/11385 [==============================] - 135s 12ms/step - loss: 0.0154 - accuracy: 0.9924 - val_loss: 0.2257 - val_accuracy: 0.9497\n",
      "Epoch 16/1000\n",
      "11385/11385 [==============================] - 132s 12ms/step - loss: 0.0154 - accuracy: 0.9940 - val_loss: 0.2195 - val_accuracy: 0.9473\n",
      "Epoch 17/1000\n",
      "11385/11385 [==============================] - 132s 12ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 0.3238 - val_accuracy: 0.9418\n",
      "Epoch 18/1000\n",
      "11385/11385 [==============================] - 127s 11ms/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.2089 - val_accuracy: 0.9473\n",
      "Epoch 19/1000\n",
      "11385/11385 [==============================] - 137s 12ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.2870 - val_accuracy: 0.9381\n",
      "Epoch 20/1000\n",
      "11385/11385 [==============================] - 134s 12ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.2317 - val_accuracy: 0.9499\n",
      "Epoch 21/1000\n",
      "11385/11385 [==============================] - 133s 12ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.2830 - val_accuracy: 0.9476\n"
     ]
    }
   ],
   "source": [
    "# RMSProp\n",
    "model.set_weights(initial_weights)\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=rms_optimizer)\n",
    "model_fit = model.fit(x=X_train, y=y_train, batch_size=1, epochs=1000, verbose=\"auto\", callbacks=[\n",
    "   average_loss_callback,\n",
    "   ModelCheckpoint(filepath=f\"model_checkpoint_{model.optimizer.get_config()['name']}.h5\",\n",
    "                   save_best_only=True,  # Only save the best performing model\n",
    "                    monitor='loss',  # Monitor the validation loss\n",
    "                    mode='min',          # Minimize the validation loss\n",
    "                    save_weights_only=False, # Save the entire model (including optimizer state)\n",
    "                    append_history=True,),\n",
    "   TensorBoard(log_dir='./logs')],\n",
    "    validation_split=0.0, validation_data=(X_val, y_val), shuffle=True, validation_batch_size=None)\n",
    "\n",
    "train_loss_list = model_fit.history['loss']\n",
    "\n",
    "num_epochs = len(model_fit.epoch)\n",
    "num_epochs_dict['rms'] = num_epochs\n",
    "loss_dict['rms'] = train_loss_list\n",
    "\n",
    "train_accuracy, val_accuracy = model_fit.history['accuracy'][-1], model_fit.history['val_accuracy'][-1]\n",
    "\n",
    "eval_dict['rms'] = (train_accuracy, val_accuracy)  \n",
    "\n",
    "with open('model_history_rmsprop.pkl', 'wb') as f:\n",
    "    pickle.dump(model_fit.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "11385/11385 [==============================] - 66s 6ms/step - loss: 0.1513 - accuracy: 0.8523 - val_loss: 0.1648 - val_accuracy: 0.8580\n",
      "Epoch 2/1000\n",
      "11385/11385 [==============================] - 69s 6ms/step - loss: 0.0847 - accuracy: 0.9256 - val_loss: 0.0708 - val_accuracy: 0.9299\n",
      "Epoch 3/1000\n",
      "11385/11385 [==============================] - 68s 6ms/step - loss: 0.0646 - accuracy: 0.9419 - val_loss: 0.0820 - val_accuracy: 0.9339\n",
      "Epoch 4/1000\n",
      "11385/11385 [==============================] - 70s 6ms/step - loss: 0.0548 - accuracy: 0.9520 - val_loss: 0.0736 - val_accuracy: 0.9404\n",
      "Epoch 5/1000\n",
      "11385/11385 [==============================] - 69s 6ms/step - loss: 0.0470 - accuracy: 0.9595 - val_loss: 0.0831 - val_accuracy: 0.9088\n",
      "Epoch 6/1000\n",
      "11385/11385 [==============================] - 69s 6ms/step - loss: 0.0392 - accuracy: 0.9664 - val_loss: 0.0679 - val_accuracy: 0.9389\n",
      "Epoch 7/1000\n",
      "11385/11385 [==============================] - 69s 6ms/step - loss: 0.0357 - accuracy: 0.9695 - val_loss: 0.0795 - val_accuracy: 0.9378\n",
      "Epoch 8/1000\n",
      "11385/11385 [==============================] - 69s 6ms/step - loss: 0.0324 - accuracy: 0.9722 - val_loss: 0.0909 - val_accuracy: 0.9270\n",
      "Epoch 9/1000\n",
      "11385/11385 [==============================] - 69s 6ms/step - loss: 0.0299 - accuracy: 0.9745 - val_loss: 0.1281 - val_accuracy: 0.9212\n",
      "Epoch 10/1000\n",
      "11385/11385 [==============================] - 67s 6ms/step - loss: 0.0287 - accuracy: 0.9765 - val_loss: 0.0681 - val_accuracy: 0.9484\n",
      "Epoch 11/1000\n",
      "11385/11385 [==============================] - 67s 6ms/step - loss: 0.0237 - accuracy: 0.9809 - val_loss: 0.0945 - val_accuracy: 0.9365\n",
      "Epoch 12/1000\n",
      "11385/11385 [==============================] - 68s 6ms/step - loss: 0.0237 - accuracy: 0.9786 - val_loss: 0.0752 - val_accuracy: 0.9373\n",
      "Epoch 13/1000\n",
      "11385/11385 [==============================] - 68s 6ms/step - loss: 0.0219 - accuracy: 0.9823 - val_loss: 0.1246 - val_accuracy: 0.9165\n",
      "Epoch 14/1000\n",
      "11385/11385 [==============================] - 68s 6ms/step - loss: 0.0183 - accuracy: 0.9859 - val_loss: 0.0730 - val_accuracy: 0.9468\n",
      "Epoch 15/1000\n",
      "11385/11385 [==============================] - 69s 6ms/step - loss: 0.0185 - accuracy: 0.9852 - val_loss: 0.0868 - val_accuracy: 0.9486\n",
      "Epoch 16/1000\n",
      "11385/11385 [==============================] - 69s 6ms/step - loss: 0.0184 - accuracy: 0.9853 - val_loss: 0.0790 - val_accuracy: 0.9502\n",
      "Epoch 17/1000\n",
      "11385/11385 [==============================] - 69s 6ms/step - loss: 0.0183 - accuracy: 0.9858 - val_loss: 0.1002 - val_accuracy: 0.9336\n"
     ]
    }
   ],
   "source": [
    "# Adam\n",
    "model.set_weights(initial_weights)\n",
    "# model = keras.models.load_model('model.14-0.10.h5')\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=adam_optimizer)\n",
    "model_fit = model.fit(x=X_train, y=y_train, batch_size=1, epochs=1000, verbose=\"auto\", callbacks=[\n",
    "   average_loss_callback,\n",
    "   ModelCheckpoint(filepath=f\"model_checkpoint_{model.optimizer.get_config()['name']}.h5\",\n",
    "                   save_best_only=True,  # Only save the best performing model\n",
    "                    monitor='loss',  # Monitor the validation loss\n",
    "                    mode='min',          # Minimize the validation loss\n",
    "                    save_weights_only=False, # Save the entire model (including optimizer state)\n",
    "                    append_history=True,),\n",
    "   TensorBoard(log_dir='./logs')],\n",
    "    validation_split=0.0, validation_data=(X_val, y_val), shuffle=True, validation_batch_size=None)\n",
    "\n",
    "train_loss_list = model_fit.history['loss']\n",
    "\n",
    "num_epochs = len(model_fit.epoch)\n",
    "num_epochs_dict['adam'] = num_epochs\n",
    "loss_dict['adam'] = train_loss_list\n",
    "\n",
    "train_accuracy, val_accuracy = model_fit.history['accuracy'][-1], model_fit.history['val_accuracy'][-1]\n",
    "\n",
    "eval_dict['adam'] = (train_accuracy, val_accuracy) \n",
    "\n",
    "with open('model_history_adam.pkl', 'wb') as f:\n",
    "    pickle.dump(model_fit.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of number of epochs it took to train each optimizer\n",
    "\n",
    "nums = []\n",
    "names = []\n",
    "for ele in num_epochs_dict:\n",
    "    if(ele == 'VGD'): continue\n",
    "    names.append(ele)\n",
    "    nums.append(num_epochs_dict[ele])\n",
    "data = pd.DataFrame({'num': nums, 'names': names})\n",
    "ax = sns.barplot(x = names, y = nums)\n",
    "\n",
    "# Set y-axis limits to integers\n",
    "ax.set_yticks(range(0, int(max(nums))+1,5))\n",
    "\n",
    "# Show the plot\n",
    "ax.set_title('number of epochs it took to train each optimizer')\n",
    "ax.set_xlabel('optimizer')\n",
    "ax.set_ylabel('number of epochs to train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of loss vs epoch for each optimizer\n",
    "\n",
    "# loss_dict.insert(0,0.55)\n",
    "# for i in loss_dict:\n",
    "#     loss_dict[i].insert(0,0.5)\n",
    "#     num_epochs_dict[i]=num_epochs_dict[i]+1\n",
    "\n",
    "for opt in loss_dict:\n",
    "    if(opt=='VGD'):continue\n",
    "    plt.plot([i for i in range(1, num_epochs_dict[opt]+1)], loss_dict[opt], label = opt)\n",
    "plt.title('plots of average training error (y-axis) vs. epochs (x-axis) ')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('average training error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rms', 'adam', 'adaGrad', 'NAG', 'momentum', 'SGD', 'VGD']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of accuracies of each optimizer\n",
    "# Heights of the bars\n",
    "opts = list(eval_dict.keys())\n",
    "bar1 = list(eval_dict[opt][0] for opt in opts)\n",
    "bar2 = list(eval_dict[opt][1] for opt in opts)\n",
    "print(opts)\n",
    "\n",
    "# Positions of the bars on the x-axis\n",
    "x_pos = range(len(bar1))\n",
    "\n",
    "# Set up the figure and axis objects\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the bars\n",
    "ax.bar(x_pos, bar1, width=0.4, color='b', label='training accuracy')\n",
    "ax.bar([i + 0.4 for i in x_pos], bar2, width=0.4, color='g', label='validation accuracy')\n",
    "\n",
    "# Set the x-axis labels and title\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(opts)\n",
    "ax.set_xlabel('optimizer')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.set_title('plot of accuracies of each optimizer')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rms', 'adam', 'adaGrad', 'NAG', 'momentum', 'SGD', 'VGD']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'generator' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(opts)\n\u001b[0;32m      8\u001b[0m \u001b[39m# Positions of the bars on the x-axis\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m x_pos \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39;49m(bar1))\n\u001b[0;32m     11\u001b[0m \u001b[39m# Set up the figure and axis objects\u001b[39;00m\n\u001b[0;32m     12\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots()\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'generator' has no len()"
     ]
    }
   ],
   "source": [
    "# plot of accuracies of each optimizer\n",
    "# Heights of the bars\n",
    "opts = list(eval_dict.keys())\n",
    "bar1 = list(eval_dict[opt][0] for opt in opts)\n",
    "bar2 = list(eval_dict[opt][1] for opt in opts)\n",
    "print(opts)\n",
    "\n",
    "# Positions of the bars on the x-axis\n",
    "x_pos = range(len(bar1))\n",
    "\n",
    "# Set up the figure and axis objects\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the bars\n",
    "ax.bar(x_pos, bar1, width=0.4, color='b', label='training accuracy')\n",
    "ax.bar([i + 0.4 for i in x_pos], bar2, width=0.4, color='g', label='validation accuracy')\n",
    "\n",
    "# Set the x-axis labels and title\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(opts)\n",
    "ax.set_xlabel('optimizer')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.set_title('plot of accuracies of each optimizer')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
