{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # full connected neural network \n",
    "# # implementing forward propogation\n",
    "\n",
    "# class fcnn:\n",
    "#     def __init__(hiddenSizes,inputDimension,outputDimension,self):\n",
    "#         self.hiddenSizes = hiddenSizes\n",
    "#         self.inputDimension = inputDimension\n",
    "#         self.outputDimension = outputDimension\n",
    "\n",
    "#         # initialising weights\n",
    "#         self.weights = []\n",
    "\n",
    "#         for i, hiddenSize in enumerate(self.hidden_sizes):\n",
    "\n",
    "# def forwardPropogation():\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Initialize weights and biases for each layer\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        # Initialize weights and biases for hidden layers\n",
    "        for i, hidden_size in enumerate(self.hidden_sizes):\n",
    "            if i == 0:\n",
    "                self.weights.append(np.random.normal(size=(self.input_size, hidden_size)))\n",
    "            else:\n",
    "                self.weights.append(np.random.normal(size=(self.hidden_sizes[i-1], hidden_size)))\n",
    "            self.biases.append(np.zeros(hidden_size))\n",
    "        \n",
    "        # Initialize weights and biases for output layer\n",
    "        self.weights.append(np.random.normal(size=(self.hidden_sizes[-1], self.output_size)))\n",
    "        self.biases.append(np.zeros(self.output_size))\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Propagate inputs through each layer\n",
    "        activations = [x]\n",
    "        for i in range(len(self.weights)):\n",
    "            z = np.dot(activations[-1], self.weights[i]) + self.biases[i]\n",
    "            a = self.sigmoid(z)\n",
    "            activations.append(a)\n",
    "        return activations\n",
    "    \n",
    "    def backward(self, x, y, activations, learning_rate):\n",
    "        # Calculate error for output layer\n",
    "        error = y - activations[-1]\n",
    "        delta = error * self.sigmoid_derivative(activations[-1])\n",
    "        \n",
    "        # Update weights and biases for output layer\n",
    "        self.weights[-1] += learning_rate * np.dot(activations[-2].T, delta)\n",
    "        self.biases[-1] += learning_rate * np.sum(delta, axis=0)\n",
    "        \n",
    "        # Calculate error for hidden layers\n",
    "        for i in range(2, len(activations)):\n",
    "            delta = np.dot(delta, self.weights[-i+1].T) * self.sigmoid_derivative(activations[-i])\n",
    "            \n",
    "            # Update weights and biases for hidden layers\n",
    "            self.weights[-i] += learning_rate * np.dot(activations[-i-1].T, delta)\n",
    "            self.biases[-i] += learning_rate * np.sum(delta, axis=0)\n",
    "        \n",
    "        # Calculate total error\n",
    "        return np.sum(error**2)\n",
    "    \n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for i in range(epochs):\n",
    "            # Forward pass\n",
    "            activations = self.forward(X)\n",
    "            \n",
    "            # Backward pass\n",
    "            error = self.backward(X, y, activations, learning_rate)\n",
    "            \n",
    "            # Print progress\n",
    "            if i % 100 == 0:\n",
    "                print(\"Epoch\", i, \"Error:\", error)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        # Forward pass\n",
    "        activations = self.forward(x)\n",
    "        \n",
    "        # Return predicted output\n",
    "        return activations[-1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b3ff50f77d03442cea5037396320163f7919f747d7cb5fcee317342f1f74448"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
